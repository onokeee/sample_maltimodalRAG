"""
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å°‚ç”¨ç‰ˆ v3.0
ğŸ†• é€šå¸¸ãƒ¢ãƒ¼ãƒ‰å‰Šé™¤ã€å¸¸ã«GPT-4 Visionã§æœ€é«˜å“è³ªã®å›ç­”
"""
import streamlit as st
import chromadb
import os
import shutil
from pathlib import Path
from dotenv import load_dotenv

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«  
from core.rag_engine import initialize_rag_system, load_and_index_documents
from core.image_handler import ImageCache
from core.multimodal_query import query_with_multimodal, render_response_with_images
from core.vectordb_browser import render_vectordb_browser, export_vectordb_summary, get_all_documents_from_vectordb
from utils.logger import get_logger
from utils.exceptions import (
    APIKeyError, FileUploadError, IndexCreationError, 
    QueryError, PDFProcessingError
)

# LlamaIndexã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
from llama_index.core import VectorStoreIndex, StorageContext, Settings
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI as LlamaOpenAI

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = get_logger()
logger.info("=" * 50)
logger.info("Application started - Multimodal Only v3.0")
logger.info("=" * 50)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v3.0",
    page_icon="ğŸ”",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "index_created" not in st.session_state:
    st.session_state.index_created = False
if "image_cache" not in st.session_state:
    st.session_state.image_cache = ImageCache()
if "embed_model" not in st.session_state:
    st.session_state.embed_model = "text-embedding-3-small"
if "llm_model" not in st.session_state:
    st.session_state.llm_model = "gpt-4o-mini"
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.1
if "use_chat_history" not in st.session_state:
    st.session_state.use_chat_history = True
if "chat_history_length" not in st.session_state:
    st.session_state.chat_history_length = 5
if "top_p" not in st.session_state:
    st.session_state.top_p = 1.0
if "frequency_penalty" not in st.session_state:
    st.session_state.frequency_penalty = 0.0
if "presence_penalty" not in st.session_state:
    st.session_state.presence_penalty = 0.0
if "seed" not in st.session_state:
    st.session_state.seed = None

# ğŸ†• èµ·å‹•æ™‚ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è‡ªå‹•ãƒ­ãƒ¼ãƒ‰
if "index" not in st.session_state:
    try:
        chroma_dir = Path("./chroma_db")
        if chroma_dir.exists() and list(chroma_dir.glob("*")):
            # ChromaDBã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰
            chroma_client = chromadb.PersistentClient(path="./chroma_db")
            collections = chroma_client.list_collections()
            
            if collections:
                # ğŸ”§ LlamaIndex Settings ã‚’åˆæœŸåŒ–ï¼ˆé‡è¦ï¼ï¼‰
                Settings.embed_model = OpenAIEmbedding(model=st.session_state.embed_model)
                Settings.llm = LlamaOpenAI(model=st.session_state.llm_model, temperature=st.session_state.temperature)
                logger.info(f"LlamaIndex Settings initialized: embed={st.session_state.embed_model}, llm={st.session_state.llm_model}")
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
                collection = collections[0]
                vector_store = ChromaVectorStore(chroma_collection=collection)
                st.session_state.index = VectorStoreIndex.from_vector_store(vector_store)
                st.session_state.index_created = True
                logger.info(f"âœ… Index auto-loaded from ChromaDB: {collection.name} ({collection.count()} documents)")
                
                # ğŸ†• ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¾©å…ƒï¼ˆVectorDBã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
                try:
                    results = collection.get(include=["metadatas"])
                    image_cache = st.session_state.image_cache
                    restored_count = 0
                    
                    for metadata in results.get("metadatas", []):
                        if "image_ids" in metadata:
                            import json
                            try:
                                if isinstance(metadata["image_ids"], str):
                                    image_ids = json.loads(metadata["image_ids"])
                                else:
                                    image_ids = metadata["image_ids"]
                                
                                # å„image_idã‚’ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²
                                for image_id in image_ids:
                                    cache_path = image_cache._get_cache_path(image_id)
                                    if cache_path.exists() and image_id not in image_cache.registry:
                                        file_size = cache_path.stat().st_size
                                        image_cache.registry[image_id] = {
                                            "path": str(cache_path),
                                            "metadata": {
                                                "file_name": metadata.get("file_name"),
                                                "page": metadata.get("page"),
                                                "type": "cached"
                                            },
                                            "size": file_size
                                        }
                                        image_cache.current_memory += file_size
                                        restored_count += 1
                            except (json.JSONDecodeError, TypeError) as e:
                                continue
                    
                    logger.info(f"âœ… Image cache restored: {restored_count} images")
                except Exception as e:
                    logger.warning(f"Failed to restore image cache: {e}")
            else:
                st.session_state.index = None
                logger.info("No collections found in ChromaDB")
        else:
            st.session_state.index = None
            logger.info("ChromaDB directory empty or not found")
    except Exception as e:
        logger.error(f"Failed to auto-load index: {e}", exc_info=True)
        st.session_state.index = None


@st.cache_resource
def get_chroma_client():
    """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—"""
    try:
        client = chromadb.PersistentClient(path="./chroma_db")
        logger.info("ChromaDB client initialized")
        return client
    except Exception as e:
        logger.error(f"Failed to initialize ChromaDB: {e}")
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


def validate_api_key(api_key):
    """APIã‚­ãƒ¼ã®æ¤œè¨¼"""
    if not api_key:
        raise APIKeyError("APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    if not api_key.startswith("sk-"):
        raise APIKeyError("ç„¡åŠ¹ãªAPIã‚­ãƒ¼å½¢å¼ã§ã™ï¼ˆsk-ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰")
    
    if len(api_key) < 20:
        raise APIKeyError("APIã‚­ãƒ¼ãŒçŸ­ã™ãã¾ã™")
    
    logger.info("API key validated successfully")
    return True


def validate_file_upload(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    max_size_mb = 100
    file_size_mb = uploaded_file.size / (1024 * 1024)
    
    if file_size_mb > max_size_mb:
        raise FileUploadError(
            f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {file_size_mb:.1f}MBï¼ˆä¸Šé™: {max_size_mb}MBï¼‰"
        )
    
    allowed_types = ['.txt', '.pdf', '.md']
    file_ext = Path(uploaded_file.name).suffix.lower()
    
    if file_ext not in allowed_types:
        raise FileUploadError(
            f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_ext}ï¼ˆå¯¾å¿œå½¢å¼: {', '.join(allowed_types)}ï¼‰"
        )
    
    logger.info(f"File upload validated: {uploaded_file.name} ({file_size_mb:.1f}MB)")
    return True


# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v3.0")
st.caption("ğŸ¤– GPT-4 Vision | ğŸ–¼ï¸ ç”»åƒç†è§£ | ğŸ” VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ | âš¡ ä¸¦åˆ—å‡¦ç†")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    api_key_input = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    if api_key_input:
        try:
            validate_api_key(api_key_input)
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")
            logger.info("API key configured")
        except APIKeyError as e:
            st.error(f"âŒ {str(e)}")
            logger.warning(f"Invalid API key: {e}")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š")
    
    # Embeddingãƒ¢ãƒ‡ãƒ«é¸æŠ
    embed_model = st.selectbox(
        "Embeddingãƒ¢ãƒ‡ãƒ«",
        options=[
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002"
        ],
        index=0,
        help="ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«"
    )
    
    # LLMãƒ¢ãƒ‡ãƒ«é¸æŠ
    llm_model = st.selectbox(
        "LLMãƒ¢ãƒ‡ãƒ«ï¼ˆå›ç­”ç”Ÿæˆï¼‰",
        options=[
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4-turbo",
            "gpt-3.5-turbo"
        ],
        index=0,
        help="è³ªå•å¿œç­”ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆç”»åƒç†è§£ã‚‚å«ã‚€ï¼‰"
    )
    
    # Temperatureè¨­å®š
    temperature = st.slider(
        "Temperature",
        min_value=0.0,
        max_value=2.0,
        value=0.1,
        step=0.1,
        help="0=ä¸€è²«æ€§é‡è¦–ã€2=å‰µé€ æ€§é‡è¦–"
    )
    
    # Top P (nucleus sampling)
    top_p = st.slider(
        "Top P",
        min_value=0.0,
        max_value=1.0,
        value=1.0,
        step=0.05,
        help="ç´¯ç©ç¢ºç‡ã®ã—ãã„å€¤ã€‚ä½ã„ã»ã©ä¿å®ˆçš„ãªå‡ºåŠ›"
    )
    
    # Frequency Penalty
    frequency_penalty = st.slider(
        "Frequency Penalty",
        min_value=0.0,
        max_value=2.0,
        value=0.0,
        step=0.1,
        help="ç¹°ã‚Šè¿”ã—ã‚’æ¸›ã‚‰ã™ã€‚é«˜ã„ã»ã©æ–°ã—ã„è¡¨ç¾ã‚’ä½¿ç”¨"
    )
    
    # Presence Penalty
    presence_penalty = st.slider(
        "Presence Penalty",
        min_value=0.0,
        max_value=2.0,
        value=0.0,
        step=0.1,
        help="æ–°ã—ã„ãƒˆãƒ”ãƒƒã‚¯ã‚’ä¿ƒé€²ã€‚é«˜ã„ã»ã©å¤šæ§˜æ€§ãŒå¢—ã™"
    )
    
    # Seedï¼ˆå†ç¾æ€§ï¼‰
    use_seed = st.checkbox("Seedå›ºå®šï¼ˆå†ç¾æ€§ï¼‰", value=False)
    seed = None
    if use_seed:
        seed = st.number_input(
            "Seedå€¤",
            min_value=0,
            max_value=999999,
            value=42,
            step=1,
            help="åŒã˜Seedã§åŒã˜çµæœã‚’å†ç¾"
        )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    st.session_state.embed_model = embed_model
    st.session_state.llm_model = llm_model
    st.session_state.temperature = temperature
    st.session_state.top_p = top_p
    st.session_state.frequency_penalty = frequency_penalty
    st.session_state.presence_penalty = presence_penalty
    st.session_state.seed = seed
    
    st.markdown("---")
    
    st.info("ğŸ¤– **GPT-4 Vision**: ç”»åƒã‚’ç†è§£ã—ã¦æ–‡ç« ä¸­ã«åŸ‹ã‚è¾¼ã¿ã¾ã™")
    
    st.markdown("---")
    
    st.subheader("ğŸ¨ ç”»åƒæŠ½å‡ºè¨­å®š")
    
    extraction_method = st.selectbox(
        "æŠ½å‡ºæ–¹æ³•",
        options=["high_quality", "medium_quality", "embedded", "combined"],
        format_func=lambda x: {
            "high_quality": "é«˜å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "medium_quality": "ä¸­å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "embedded": "åŸ‹ã‚è¾¼ã¿ç”»åƒï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰",
            "combined": "å…¨ã¦ï¼ˆãƒšãƒ¼ã‚¸+åŸ‹ã‚è¾¼ã¿ï¼‰"
        }[x],
        index=0
    )
    
    if extraction_method in ["high_quality", "medium_quality", "combined"]:
        dpi = st.slider("è§£åƒåº¦ï¼ˆDPIï¼‰", 72, 300, 200, 50)
    else:
        dpi = 150
    
    max_workers = st.slider(
        "ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰æ•°",
        min_value=1,
        max_value=5,
        value=3,
        help="PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ä¸¦åˆ—åŒ–ã—ã¾ã™ï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰"
    )
    
    st.markdown("---")
    
    st.subheader("ğŸ’¬ è³ªå•å¿œç­”è¨­å®š")
    
    # ä¼šè©±å±¥æ­´ã‚’ä½¿ç”¨
    use_chat_history = st.checkbox(
        "ä¼šè©±å±¥æ­´ã‚’è€ƒæ…£",
        value=True,
        help="éå»ã®ä¼šè©±ã‚’è€ƒæ…£ã—ãŸå›ç­”ã‚’ç”Ÿæˆ"
    )
    
    # ä¼šè©±å±¥æ­´ã®é•·ã•
    chat_history_length = 5
    if use_chat_history:
        chat_history_length = st.slider(
            "ä¼šè©±å±¥æ­´æ•°",
            min_value=1,
            max_value=20,
            value=5,
            help="ä½•ã‚¿ãƒ¼ãƒ³åˆ†ã®ä¼šè©±ã‚’è€ƒæ…£ã™ã‚‹ã‹"
        )
    
    # æ¤œç´¢çµæœä»¶æ•°
    similarity_top_k = st.slider(
        "æ¤œç´¢çµæœä»¶æ•°",
        min_value=1,
        max_value=10,
        value=3,
        help="é¡ä¼¼åº¦ãŒé«˜ã„ä¸Šä½Nä»¶ã‚’å–å¾—"
    )
    
    # Max Tokens
    max_tokens = st.number_input(
        "Max Tokens",
        min_value=100,
        max_value=4000,
        value=2000,
        step=100,
        help="å›ç­”ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°"
    )
    
    # ç”»åƒè©³ç´°ãƒ¬ãƒ™ãƒ«
    image_detail = st.selectbox(
        "ç”»åƒè©³ç´°ãƒ¬ãƒ™ãƒ«",
        options=["high", "low", "auto"],
        index=0,
        help="high=é«˜ç”»è³ªã€low=ä½ã‚³ã‚¹ãƒˆã€auto=è‡ªå‹•"
    )
    
    # æœ€å¤§ç”»åƒæ•°
    max_images = st.slider(
        "æœ€å¤§ç”»åƒæ•°",
        min_value=1,
        max_value=10,
        value=5,
        help="1å›ã®è³ªå•ã§é€ä¿¡ã™ã‚‹ç”»åƒã®æœ€å¤§æ•°"
    )
    
    # Response Mode
    response_mode = st.selectbox(
        "Response Mode",
        options=["compact", "tree_summarize", "simple_summarize"],
        index=0,
        help="compact=ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã€tree_summarize=éšå±¤è¦ç´„ã€simple_summarize=ã‚·ãƒ³ãƒ—ãƒ«è¦ç´„"
    )
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    st.session_state.use_chat_history = use_chat_history
    st.session_state.chat_history_length = chat_history_length
    st.session_state.max_tokens = max_tokens
    st.session_state.image_detail = image_detail
    st.session_state.max_images = max_images
    st.session_state.response_mode = response_mode
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    data_dir = Path("./uploaded_data")
    if data_dir.exists():
        files = list(data_dir.glob("*.*"))
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", len(files))
    else:
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", 0)
    
    total_images = len(st.session_state.image_cache.registry)
    if total_images > 0:
        st.metric("ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥", total_images)
        cache_size_mb = st.session_state.image_cache.current_memory / (1024 * 1024)
        st.caption(f"ä½¿ç”¨é‡: {cache_size_mb:.1f}MB")
    
    if st.session_state.index_created:
        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ¸ˆã¿")
    else:
        st.info("â„¹ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ")
    
    st.markdown("---")
    
    st.subheader("ğŸ‘ï¸ è¡¨ç¤ºè¨­å®š")
    show_sources = st.checkbox("å‚ç…§å…ƒã‚’è¡¨ç¤º", value=True)
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", type="secondary"):
        if st.session_state.get("confirm_reset", False):
            try:
                if data_dir.exists():
                    shutil.rmtree(data_dir)
                    data_dir.mkdir()
                
                chroma_dir = Path("./chroma_db")
                if chroma_dir.exists():
                    shutil.rmtree(chroma_dir)
                    chroma_dir.mkdir()
                
                st.session_state.image_cache.clear()
                st.session_state.index_created = False
                st.session_state.messages = []
                st.cache_resource.clear()
                
                st.success("âœ… ãƒªã‚»ãƒƒãƒˆå®Œäº†")
                logger.info("All data reset successfully")
                st.session_state.confirm_reset = False
                st.rerun()
            except Exception as e:
                st.error(f"âŒ ãƒªã‚»ãƒƒãƒˆå¤±æ•—: {e}")
                logger.error(f"Reset failed: {e}")
        else:
            st.session_state.confirm_reset = True
            st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèª")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not api_key_input:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†", 
    "ğŸ’¬ è³ªå•å¿œç­”", 
    "ğŸ” VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼",
    "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"
])

# ã‚¿ãƒ–1: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†
with tab1:
    st.header("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
            accept_multiple_files=True,
            type=["txt", "pdf", "md"],
            help="å¯¾å¿œå½¢å¼: .txt, .pdf, .mdï¼ˆæœ€å¤§100MB/ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
        )
        
        if uploaded_files:
            data_dir = Path("./uploaded_data")
            data_dir.mkdir(exist_ok=True)
            
            success_count = 0
            error_count = 0
            
            for uploaded_file in uploaded_files:
                try:
                    validate_file_upload(uploaded_file)
                    file_path = data_dir / uploaded_file.name
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    success_count += 1
                    logger.info(f"File uploaded: {uploaded_file.name}")
                except FileUploadError as e:
                    st.error(f"âŒ {uploaded_file.name}: {str(e)}")
                    error_count += 1
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ - {str(e)}")
                    error_count += 1
            
            if success_count > 0:
                st.success(f"âœ… {success_count}ä»¶ä¿å­˜å®Œäº†")
            if error_count > 0:
                st.warning(f"âš ï¸ {error_count}ä»¶å¤±æ•—")
    
    with col2:
        st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†")
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            files = sorted(data_dir.glob("*.*"))
            if files:
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files)}**")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰
                if st.checkbox("ğŸ—‘ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãƒ¢ãƒ¼ãƒ‰", key="file_delete_mode"):
                    st.warning("å‰Šé™¤ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    
                    files_to_delete = []
                    for file in files:
                        size_kb = file.stat().st_size / 1024
                        icon = "ğŸ“„" if file.suffix.lower() == ".pdf" else "ğŸ“"
                        
                        if st.checkbox(
                            f"{icon} {file.name} ({size_kb:.1f}KB)",
                            key=f"del_{file.name}"
                        ):
                            files_to_delete.append(file)
                    
                    if files_to_delete:
                        col_del1, col_del2 = st.columns(2)
                        with col_del1:
                            if st.button("ğŸ—‘ï¸ å‰Šé™¤å®Ÿè¡Œ", type="primary", use_container_width=True):
                                deleted_count = 0
                                for file in files_to_delete:
                                    try:
                                        file.unlink()
                                        deleted_count += 1
                                        logger.info(f"File deleted: {file.name}")
                                    except Exception as e:
                                        st.error(f"å‰Šé™¤å¤±æ•—: {file.name} - {e}")
                                        logger.error(f"Failed to delete file: {file.name} - {e}")
                                
                                if deleted_count > 0:
                                    st.success(f"âœ… {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                    st.rerun()
                        with col_del2:
                            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                                st.rerun()
                else:
                    # é€šå¸¸è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
                    for file in files:
                        size_kb = file.stat().st_size / 1024
                        icon = "ğŸ“„" if file.suffix.lower() == ".pdf" else "ğŸ“"
                        st.text(f"{icon} {file.name} ({size_kb:.1f}KB)")
            else:
                st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        else:
            st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    st.markdown("---")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆãƒ¢ãƒ¼ãƒ‰é¸æŠ
    col_mode1, col_mode2 = st.columns(2)
    with col_mode1:
        if st.button("ğŸ”¨ æ–°è¦ä½œæˆï¼ˆä¸Šæ›¸ãï¼‰", type="primary", use_container_width=True):
            st.session_state.index_mode = "overwrite"
            st.session_state.selected_files = None
    with col_mode2:
        if st.button("â• è¿½åŠ ä½œæˆ", type="secondary", use_container_width=True):
            st.session_state.index_mode = "append"
            st.session_state.selected_files = None
    
    # è¿½åŠ ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ UI ã‚’è¡¨ç¤º
    if st.session_state.get("index_mode") == "append" and st.session_state.get("selected_files") is None:
        st.info("ğŸ“ è¿½åŠ ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            all_files = sorted([f for f in data_dir.glob("*.*")])
            
            if all_files:
                st.write("ğŸ“¦ **ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§**")
                
                selected_files = []
                select_all = st.checkbox("â˜‘ï¸ å…¨ã¦é¸æŠ", value=False)
                
                for file in all_files:
                    size_kb = file.stat().st_size / 1024
                    icon = "ğŸ“„" if file.suffix.lower() == ".pdf" else "ğŸ“"
                    default_checked = select_all
                    
                    if st.checkbox(
                        f"{icon} {file.name} ({size_kb:.1f}KB)",
                        value=default_checked,
                        key=f"file_select_{file.name}"
                    ):
                        selected_files.append(file.name)
                
                st.markdown("---")
                
                col_confirm1, col_confirm2 = st.columns(2)
                with col_confirm1:
                    if st.button("âœ… é¸æŠã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã§è¿½åŠ ", type="primary", use_container_width=True):
                        if selected_files:
                            st.session_state.selected_files = selected_files
                            st.rerun()
                        else:
                            st.warning("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
                with col_confirm2:
                    if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                        st.session_state.index_mode = None
                        st.rerun()
            else:
                st.warning("âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                st.session_state.index_mode = None
        else:
            st.error("âŒ uploaded_dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            st.session_state.index_mode = None
    
    # ãƒ¢ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã¦ã€ä¸”ã¤è¿½åŠ ãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠæ¸ˆã¿ã®å ´åˆã®ã¿å‡¦ç†å®Ÿè¡Œ
    if "index_mode" in st.session_state and st.session_state.index_mode:
        mode = st.session_state.index_mode
        
        # è¿½åŠ ãƒ¢ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ãŒæœªé¸æŠã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if mode == "append" and st.session_state.get("selected_files") is None:
            pass
        else:
            data_dir = Path("./uploaded_data")
            
            if not data_dir.exists() or not list(data_dir.glob("*.*")):
                st.error("âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                st.session_state.index_mode = None
                st.session_state.selected_files = None
            else:
                try:
                    # è¿½åŠ ãƒ¢ãƒ¼ãƒ‰ã§é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‡¦ç†
                    if mode == "append" and st.session_state.get("selected_files"):
                        temp_dir = Path("./temp_selected_files")
                        if temp_dir.exists():
                            shutil.rmtree(temp_dir)
                        temp_dir.mkdir()
                        
                        selected_file_names = st.session_state.selected_files
                        for file_name in selected_file_names:
                            src = data_dir / file_name
                            dst = temp_dir / file_name
                            if src.exists():
                                shutil.copy2(src, dst)
                                logger.info(f"Selected for indexing: {file_name}")
                        
                        target_dir = temp_dir
                        logger.info(f"Processing {len(selected_file_names)} selected files")
                    else:
                        target_dir = data_dir
                    
                    mode_label = "æ–°è¦ä½œæˆï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼‰" if mode == "overwrite" else f"è¿½åŠ ä½œæˆï¼ˆ{len(st.session_state.get('selected_files', []))}ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
                    with st.spinner(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’{mode_label}ä¸­..."):
                        chroma_client = get_chroma_client()
                        
                        if chroma_client is None:
                            raise IndexCreationError("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        
                        if mode == "overwrite":
                            storage_context = initialize_rag_system(chroma_client)
                        else:
                            try:
                                collection = chroma_client.get_collection("multimodal_rag")
                                vector_store = ChromaVectorStore(chroma_collection=collection)
                                storage_context = StorageContext.from_defaults(vector_store=vector_store)
                                logger.info("Using existing collection for append mode")
                            except Exception:
                                storage_context = initialize_rag_system(chroma_client)
                                logger.info("No existing collection, creating new one")
                        
                        index, error = load_and_index_documents(
                            str(target_dir),
                            storage_context,
                            extraction_method,
                            dpi,
                            max_workers=max_workers
                        )
                        
                        if mode == "append" and 'temp_dir' in locals() and temp_dir.exists():
                            shutil.rmtree(temp_dir)
                            logger.info("Cleaned up temporary directory")
                        
                        if error:
                            raise IndexCreationError(error)
                        
                        st.session_state.index = index
                        st.session_state.index_created = True
                        
                        success_msg = "âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸï¼" if mode == "overwrite" else f"âœ… {len(st.session_state.get('selected_files', []))}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼"
                        st.success(success_msg)
                        st.balloons()
                        
                        st.session_state.index_mode = None
                        st.session_state.selected_files = None
                
                except (IndexCreationError, PDFProcessingError) as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    st.session_state.index_mode = None
                    st.session_state.selected_files = None
                    if 'temp_dir' in locals() and temp_dir.exists():
                        shutil.rmtree(temp_dir)
                except Exception as e:
                    st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    with st.expander("è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                        st.code(str(e))
                    st.session_state.index_mode = None
                    st.session_state.selected_files = None
                    if 'temp_dir' in locals() and temp_dir.exists():
                        shutil.rmtree(temp_dir)
    
    st.markdown("---")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‰Šé™¤æ©Ÿèƒ½
    st.markdown("---")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†æ©Ÿèƒ½
    if st.session_state.index_created:
        st.subheader("ğŸ—‘ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†")
        
        # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†ã‘ã‚‹
        idx_tab1, idx_tab2 = st.tabs(["å€‹åˆ¥å‰Šé™¤", "å…¨å‰Šé™¤"])
        
        with idx_tab1:
            st.write("**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ**")
            
            # VectorDBã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
            chroma_client = get_chroma_client()
            if chroma_client:
                try:
                    collection = chroma_client.get_collection("multimodal_rag")
                    results = collection.get(include=["metadatas"])
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                    file_dict = {}
                    for idx, metadata in enumerate(results.get("metadatas", [])):
                        file_name = metadata.get("file_name", "Unknown")
                        if file_name not in file_dict:
                            file_dict[file_name] = []
                        file_dict[file_name].append(results["ids"][idx])
                    
                    if file_dict:
                        files_to_delete = []
                        for file_name, doc_ids in sorted(file_dict.items()):
                            chunk_count = len(doc_ids)
                            if st.checkbox(
                                f"ğŸ“„ {file_name} ({chunk_count}ãƒãƒ£ãƒ³ã‚¯)",
                                key=f"idx_del_{file_name}"
                            ):
                                files_to_delete.append((file_name, doc_ids))
                        
                        if files_to_delete:
                            st.markdown("---")
                            col_idx1, col_idx2 = st.columns(2)
                            with col_idx1:
                                if st.button("ğŸ—‘ï¸ é¸æŠãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤", type="primary", use_container_width=True):
                                    try:
                                        deleted_files = []
                                        for file_name, doc_ids in files_to_delete:
                                            # ChromaDBã‹ã‚‰å‰Šé™¤
                                            collection.delete(ids=doc_ids)
                                            deleted_files.append(file_name)
                                            logger.info(f"Index deleted for file: {file_name} ({len(doc_ids)} chunks)")
                                        
                                        # ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒã‚’å‰Šé™¤
                                        image_cache = st.session_state.image_cache
                                        for file_name in deleted_files:
                                            # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”»åƒã‚’æ¢ã—ã¦å‰Šé™¤
                                            images_to_remove = []
                                            for image_id, info in image_cache.registry.items():
                                                if info["metadata"].get("file_name") == file_name:
                                                    images_to_remove.append(image_id)
                                            
                                            for image_id in images_to_remove:
                                                cache_path = Path(image_cache.registry[image_id]["path"])
                                                if cache_path.exists():
                                                    cache_path.unlink()
                                                image_cache.current_memory -= image_cache.registry[image_id]["size"]
                                                del image_cache.registry[image_id]
                                                logger.info(f"Image cache deleted: {image_id}")
                                        
                                        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†èª­ã¿è¾¼ã¿
                                        remaining_count = collection.count()
                                        if remaining_count > 0:
                                            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
                                            vector_store = ChromaVectorStore(chroma_collection=collection)
                                            st.session_state.index = VectorStoreIndex.from_vector_store(vector_store)
                                            st.success(f"âœ… {len(deleted_files)}ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                        else:
                                            # ã™ã¹ã¦å‰Šé™¤ã•ã‚ŒãŸå ´åˆ
                                            st.session_state.index = None
                                            st.session_state.index_created = False
                                            st.success("âœ… ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ")
                                        
                                        st.balloons()
                                        st.rerun()
                                    except Exception as e:
                                        st.error(f"âŒ å‰Šé™¤å¤±æ•—: {e}")
                                        logger.error(f"Index deletion failed: {e}")
                            with col_idx2:
                                if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                                    st.rerun()
                        else:
                            st.info("â„¹ï¸ å‰Šé™¤ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    else:
                        st.info("â„¹ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                    logger.error(f"Failed to get indexed files: {e}")
        
        with idx_tab2:
            st.warning("âš ï¸ ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™")
            
            if st.button("ğŸ—‘ï¸ ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤", type="secondary", use_container_width=True):
                if st.session_state.get("confirm_index_delete_all", False):
                    try:
                        # ChromaDBã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
                        chroma_client = get_chroma_client()
                        if chroma_client:
                            try:
                                chroma_client.delete_collection("multimodal_rag")
                                logger.info("ChromaDB collection deleted")
                            except Exception as e:
                                logger.warning(f"Collection deletion warning: {e}")
                        
                        # ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                        st.session_state.image_cache.clear()
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                        st.session_state.index = None
                        st.session_state.index_created = False
                        st.session_state.messages = []
                        
                        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                        st.cache_resource.clear()
                        
                        st.success("âœ… ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                        logger.info("All indexes deleted successfully")
                        st.session_state.confirm_index_delete_all = False
                        st.balloons()
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ å‰Šé™¤å¤±æ•—: {e}")
                        logger.error(f"Index deletion failed: {e}")
                        st.session_state.confirm_index_delete_all = False
                else:
                    st.session_state.confirm_index_delete_all = True
                    st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„")
                    st.info("ğŸ“ æ³¨æ„: ã™ã¹ã¦ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒå‰Šé™¤ã•ã‚Œã¾ã™")
    else:
        st.info("â„¹ï¸ å‰Šé™¤å¯èƒ½ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")

# ã‚¿ãƒ–2: è³ªå•å¿œç­”ï¼ˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å°‚ç”¨ï¼‰
with tab2:
    st.header("ğŸ’¬ è³ªå•å¿œç­”")
    
    if not st.session_state.index_created:
        st.warning("âš ï¸ ã¾ãšã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
    else:
        chat_container = st.container(height=500)
        
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if (message["role"] == "assistant" and 
                        message.get("is_multimodal", False) and 
                        "image_documents" in message):
                        render_response_with_images(message["content"], message["image_documents"])
                    else:
                        st.markdown(message["content"])
                    
                    if show_sources and "sources" in message and message["sources"]:
                        with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                            for i, source in enumerate(message["sources"]):
                                st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source.get('file_name', 'Unknown')} (Page {source.get('page', '?')})")
                                st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                                st.text(source["text"][:200] + "...")
                                st.divider()
        
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)
            
            with chat_container:
                with st.chat_message("assistant"):
                    message_placeholder = st.empty()
                    message_placeholder.markdown("â— å›ç­”ã‚’ç”Ÿæˆä¸­...")
                    
                    result = query_with_multimodal(
                        st.session_state.index,
                        prompt,
                        similarity_top_k=similarity_top_k,
                        max_tokens=st.session_state.get("max_tokens", 2000),
                        image_detail=st.session_state.get("image_detail", "high"),
                        max_images=st.session_state.get("max_images", 5),
                        response_mode=st.session_state.get("response_mode", "compact"),
                        use_chat_history=st.session_state.get("use_chat_history", True),
                        chat_history_length=st.session_state.get("chat_history_length", 5),
                        top_p=st.session_state.get("top_p", 1.0),
                        frequency_penalty=st.session_state.get("frequency_penalty", 0.0),
                        presence_penalty=st.session_state.get("presence_penalty", 0.0),
                        seed=st.session_state.get("seed", None)
                    )
                    
                    if result["success"]:
                        message_placeholder.empty()
                        if result["image_documents"]:
                            render_response_with_images(result["answer"], result["image_documents"])
                        else:
                            st.markdown(result["answer"])
                        
                        sources = []
                        for node in result["source_nodes"]:
                            sources.append({
                                "text": node.text,
                                "score": node.score,
                                "file_name": node.metadata.get("file_name", "Unknown"),
                                "page": node.metadata.get("page", "?")
                            })
                        
                        if show_sources and sources:
                            with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                                for i, source in enumerate(sources):
                                    st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source.get('file_name', 'Unknown')} (Page {source.get('page', '?')})")
                                    st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                                    st.text(source["text"][:200] + "...")
                                    st.divider()
                        
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": result["answer"],
                            "sources": sources,
                            "image_documents": result["image_documents"],
                            "is_multimodal": True
                        })
                        
                        logger.info(f"Query answered: {prompt[:50]}...")
                    else:
                        message_placeholder.markdown(f"âŒ {result['answer']}")
                        
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"âŒ {result['answer']}",
                            "sources": [],
                            "is_multimodal": False
                        })
                        logger.error(f"Query failed: {result['answer']}")
            
            st.rerun()

# ã‚¿ãƒ–3: VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼
with tab3:
    chroma_client = get_chroma_client()
    if chroma_client:
        documents = get_all_documents_from_vectordb(chroma_client)
        
        if not documents:
            st.warning("âš ï¸ VectorDBã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            st.info("ã€ŒğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ã€ã‚¿ãƒ–ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
        else:
            render_vectordb_browser(chroma_client, st.session_state.image_cache)
            
            st.markdown("---")
            export_vectordb_summary(documents)

# ã‚¿ãƒ–4: ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
with tab4:
    st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ’¾ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸")
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            total_size = sum(f.stat().st_size for f in data_dir.glob("*.*"))
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º", f"{total_size / (1024*1024):.1f} MB")
        
        chroma_dir = Path("./chroma_db")
        if chroma_dir.exists():
            chroma_size = sum(f.stat().st_size for f in chroma_dir.rglob("*") if f.is_file())
            st.metric("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º", f"{chroma_size / (1024*1024):.1f} MB")
        
        cache_dir = Path("./image_cache")
        if cache_dir.exists():
            cache_size = sum(f.stat().st_size for f in cache_dir.glob("*") if f.is_file())
            st.metric("ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º", f"{cache_size / (1024*1024):.1f} MB")
    
    with col2:
        st.subheader("ğŸ“ˆ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹")
        st.metric("ãƒãƒ£ãƒƒãƒˆå±¥æ­´", len(st.session_state.messages))
        st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”»åƒæ•°", len(st.session_state.image_cache.registry))
        
        if st.session_state.index_created:
            st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: ä½œæˆæ¸ˆã¿")
        else:
            st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: æœªä½œæˆ")
    
    st.markdown("---")
    
    st.subheader("ğŸ“ æœ€æ–°ãƒ­ã‚°")
    log_dir = Path("./logs")
    if log_dir.exists():
        log_files = sorted(log_dir.glob("*.log"), key=lambda x: x.stat().st_mtime, reverse=True)
        if log_files:
            latest_log = log_files[0]
            with open(latest_log, 'r', encoding='utf-8') as f:
                log_content = f.readlines()
            
            st.text(f"ãƒ•ã‚¡ã‚¤ãƒ«: {latest_log.name}")
            st.code("".join(log_content[-20:]), language="log")
        else:
            st.info("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v3.0 | ğŸ¤– GPT-4 Visionå°‚ç”¨ | ğŸ–¼ï¸ ç”»åƒç†è§£ | ğŸ” VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼
    </div>
    """,
    unsafe_allow_html=True
)