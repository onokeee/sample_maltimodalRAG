"""
VectorDBÂèØË¶ñÂåñ„É¢„Ç∏„É•„Éº„É´ - „É°„Çø„Éá„Éº„ÇøÁ∑®ÈõÜÊ©üËÉΩ‰ªò„Åç
ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„ÉÜ„Ç≠„Çπ„Éà„Å®ÁîªÂÉè„ÅÆÈñ¢‰øÇ„ÇíË°®Á§∫ + „É°„Çø„Éá„Éº„ÇøÁÆ°ÁêÜ
"""
import json
import streamlit as st
from pathlib import Path
import chromadb
from utils.logger import get_logger
from core.metadata_utils import (
    get_file_list,
    get_file_metadata,
    update_file_metadata,
    bulk_update_metadata,
    preview_bulk_update
)

logger = get_logger()


def get_all_documents_from_vectordb(chroma_client, collection_name="multimodal_rag"):
    """
    VectorDB„Åã„ÇâÂÖ®„Éâ„Ç≠„É•„É°„É≥„Éà„ÇíÂèñÂæó
    """
    try:
        collections = chroma_client.list_collections()
        logger.info(f"Available collections: {[c.name for c in collections]}")
        
        if not any(c.name == collection_name for c in collections):
            if collections:
                collection_name = collections[0].name
                logger.info(f"Using collection: {collection_name}")
            else:
                logger.warning("No collections found in VectorDB")
                return []
        
        collection = chroma_client.get_collection(collection_name)
        
        results = collection.get(
            include=["documents", "metadatas", "embeddings"]
        )
        
        logger.info(f"Retrieved {len(results['ids'])} documents from VectorDB (collection: {collection_name})")
        
        documents = []
        for i in range(len(results['ids'])):
            if results['embeddings'] is not None and len(results['embeddings']) > 0:
                embedding_size = len(results['embeddings'][i]) if results['embeddings'][i] is not None else 0
            else:
                embedding_size = 0
            
            doc = {
                "id": results['ids'][i],
                "text": results['documents'][i],
                "metadata": results['metadatas'][i],
                "embedding_size": embedding_size
            }
            documents.append(doc)
        
        return documents
    
    except Exception as e:
        logger.error(f"Failed to retrieve documents: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return []


def group_documents_by_file(documents):
    """
    „Éâ„Ç≠„É•„É°„É≥„Éà„Çí„Éï„Ç°„Ç§„É´„Åî„Å®„Å´„Ç∞„É´„Éº„ÉóÂåñ
    """
    grouped = {}
    
    for doc in documents:
        file_name = doc['metadata'].get('file_name', 'Unknown')
        if file_name not in grouped:
            grouped[file_name] = []
        grouped[file_name].append(doc)
    
    for file_name in grouped:
        grouped[file_name].sort(key=lambda x: x['metadata'].get('page', 0))
    
    return grouped


def render_vectordb_browser(chroma_client, image_cache):
    """
    VectorDB„Éñ„É©„Ç¶„Ç∂„ÉºUI - 3„Çø„ÉñÊßãÊàê
    """
    st.header("üîç VectorDB „Éñ„É©„Ç¶„Ç∂„Éº")
    st.caption("ÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Çã„ÉÜ„Ç≠„Çπ„Éà„Å®ÁîªÂÉè„ÅÆÈñ¢‰øÇ„ÇíÁ¢∫Ë™ç + „É°„Çø„Éá„Éº„ÇøÁÆ°ÁêÜ")
    
    documents = get_all_documents_from_vectordb(chroma_client)
    
    if not documents:
        st.warning("‚ö†Ô∏è VectorDB„Å´„Éâ„Ç≠„É•„É°„É≥„Éà„ÅåÁôªÈå≤„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì")
        st.info("„Äåüìö „Éâ„Ç≠„É•„É°„É≥„ÉàÁÆ°ÁêÜ„Äç„Çø„Éñ„Åß„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    # Áµ±Ë®àÊÉÖÂ†±
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Á∑è„ÉÅ„É£„É≥„ÇØÊï∞", len(documents))
    
    with col2:
        total_images = sum(doc['metadata'].get('num_images', 0) for doc in documents)
        st.metric("Á∑èÁîªÂÉèÊï∞", total_images)
    
    with col3:
        unique_files = len(set(doc['metadata'].get('file_name') for doc in documents))
        st.metric("„Éï„Ç°„Ç§„É´Êï∞", unique_files)
    
    with col4:
        avg_text_length = sum(len(doc['text']) for doc in documents) / len(documents)
        st.metric("Âπ≥ÂùáÊñáÂ≠óÊï∞", f"{avg_text_length:.0f}")
    
    st.markdown("---")
    
    # 3„Çø„ÉñÊßãÊàê
    tab1, tab2, tab3 = st.tabs([
        "üìñ Èñ≤Ë¶ß„É¢„Éº„Éâ",
        "‚úèÔ∏è ÂÄãÂà•Á∑®ÈõÜ",
        "‚ö° ‰∏ÄÊã¨ÁÆ°ÁêÜ"
    ])
    
    with tab1:
        render_browse_mode(chroma_client, documents, image_cache)
    
    with tab2:
        render_individual_editor(chroma_client)
    
    with tab3:
        render_bulk_manager(chroma_client)


def render_browse_mode(chroma_client, documents, image_cache):
    """Èñ≤Ë¶ß„É¢„Éº„ÉâÔºàÊó¢Â≠òÊ©üËÉΩÔºâ"""
    grouped_docs = group_documents_by_file(documents)
    
    view_mode = st.radio(
        "Ë°®Á§∫„É¢„Éº„Éâ",
        options=["„Éï„Ç°„Ç§„É´Âà•", "ÂÖ®„Éö„Éº„Ç∏‰∏ÄË¶ß", "ÁîªÂÉè‰ªò„Åç„ÅÆ„Åø"],
        horizontal=True
    )
    
    st.markdown("---")
    
    if view_mode == "„Éï„Ç°„Ç§„É´Âà•":
        render_by_file(grouped_docs, image_cache)
    elif view_mode == "ÂÖ®„Éö„Éº„Ç∏‰∏ÄË¶ß":
        render_all_pages(documents, image_cache)
    elif view_mode == "ÁîªÂÉè‰ªò„Åç„ÅÆ„Åø":
        render_with_images_only(documents, image_cache)


def render_individual_editor(chroma_client):
    """ÂÄãÂà•Á∑®ÈõÜ„Çø„Éñ"""
    st.subheader("‚úèÔ∏è „Éï„Ç°„Ç§„É´Âà•„É°„Çø„Éá„Éº„ÇøÁ∑®ÈõÜ")
    st.caption("ÂêÑ„Éï„Ç°„Ç§„É´Âõ∫Êúâ„ÅÆÊÉÖÂ†±„ÇíÂÄãÂà•„Å´Ë®≠ÂÆö„Åß„Åç„Åæ„Åô")
    
    # „Éï„Ç°„Ç§„É´‰∏ÄË¶ßÂèñÂæó
    files = get_file_list(chroma_client)
    
    if not files:
        st.info("„Éï„Ç°„Ç§„É´„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        return
    
    st.info(f"üìä ÂÖ®{len(files)}„Éï„Ç°„Ç§„É´")
    
    # „Éï„Ç°„Ç§„É´„Åî„Å®„Å´Á∑®ÈõÜUI
    for file_name, info in sorted(files.items()):
        with st.expander(
            f"üìÑ {file_name} ({info['page_count']}„Éö„Éº„Ç∏ / {info['chunk_count']}„ÉÅ„É£„É≥„ÇØ)",
            expanded=False
        ):
            render_file_editor(chroma_client, file_name, info)


def render_file_editor(chroma_client, file_name, info):
    """ÂÄãÂà•„Éï„Ç°„Ç§„É´„ÅÆÁ∑®ÈõÜUI"""
    metadata = info["metadata"]
    
    st.write("**ÁèæÂú®„ÅÆ„É°„Çø„Éá„Éº„Çø:**")
    
    # 2„Ç´„É©„É†„É¨„Ç§„Ç¢„Ç¶„Éà
    col1, col2 = st.columns(2)
    
    with col1:
        product_type = st.text_input(
            "Ë£ΩÂìÅÁ®ÆÂà•",
            value=metadata.get("product_type", ""),
            key=f"product_{file_name}",
            help="‰æã: „Ç®„Ç¢„Ç≥„É≥„ÄÅÊ¥óÊøØÊ©ü„ÄÅÂÜ∑ËîµÂ∫´"
        )
        
        model = st.text_input(
            "ÂûãÁï™",
            value=metadata.get("model", ""),
            key=f"model_{file_name}",
            help="‰æã: AÂûã„ÄÅBÂûã"
        )
        
        model_number = st.text_input(
            "ÂìÅÁï™",
            value=metadata.get("model_number", ""),
            key=f"number_{file_name}",
            help="‰æã: RAS-X40K"
        )
    
    with col2:
        manufacturer = st.text_input(
            "„É°„Éº„Ç´„Éº",
            value=metadata.get("manufacturer", ""),
            key=f"manu_{file_name}",
            help="‰æã: „Äá„ÄáÈõªÊ©ü"
        )
        
        category = st.text_input(
            "„Ç´„ÉÜ„Ç¥„É™",
            value=metadata.get("category", ""),
            key=f"cat_{file_name}",
            help="‰æã: ÂÜ∑ÊöñÊàøÊ©üÂô®„ÄÅÂÆ∂Èõª"
        )
        
        tags = st.text_input(
            "„Çø„Ç∞Ôºà„Ç´„É≥„ÉûÂå∫Âàá„ÇäÔºâ",
            value=metadata.get("tags", ""),
            key=f"tags_{file_name}",
            help="‰æã: Ê•≠ÂãôÁî®, 2023Âπ¥„É¢„Éá„É´"
        )
    
    # ÂÇôËÄÉÊ¨Ñ
    notes = st.text_area(
        "ÂÇôËÄÉ„Éª„É°„É¢",
        value=metadata.get("notes", ""),
        key=f"notes_{file_name}",
        height=100,
        help="Ëá™Áî±Ë®òËø∞Ê¨Ñ"
    )
    
    # ‰øùÂ≠ò„Éú„Çø„É≥
    col_btn1, col_btn2 = st.columns([3, 1])
    
    with col_btn1:
        if st.button(
            f"üíæ „Åì„ÅÆ„Éï„Ç°„Ç§„É´„Å´ÈÅ©Áî®Ôºà{info['chunk_count']}„ÉÅ„É£„É≥„ÇØÔºâ",
            key=f"save_{file_name}",
            type="primary",
            use_container_width=True
        ):
            try:
                new_metadata = {
                    "product_type": product_type,
                    "model": model,
                    "model_number": model_number,
                    "manufacturer": manufacturer,
                    "category": category,
                    "tags": tags,
                    "notes": notes
                }
                
                # Á©∫„ÅÆÂÄ§„ÅØÂê´„ÇÅ„Å™„ÅÑ
                new_metadata = {k: v for k, v in new_metadata.items() if v}
                
                count = update_file_metadata(chroma_client, file_name, new_metadata)
                st.success(f"‚úÖ {count}„ÉÅ„É£„É≥„ÇØ„ÇíÊõ¥Êñ∞„Åó„Åæ„Åó„Åü")
                st.balloons()
                
                # Â∞ë„ÅóÂæÖ„Å£„Å¶„Åã„Çâ„É™„É≠„Éº„Éâ
                import time
                time.sleep(1)
                st.rerun()
                
            except Exception as e:
                st.error(f"‚ùå Êõ¥Êñ∞Â§±Êïó: {e}")
                logger.error(f"Metadata update failed for {file_name}: {e}")
    
    with col_btn2:
        # ÁèæÂú®„ÅÆ„É°„Çø„Éá„Éº„ÇøË°®Á§∫
        with st.popover("üìã Ë©≥Á¥∞"):
            st.json(metadata)


def render_bulk_manager(chroma_client):
    """‰∏ÄÊã¨ÁÆ°ÁêÜ„Çø„Éñ"""
    st.subheader("‚ö° ‰∏ÄÊã¨„É°„Çø„Éá„Éº„ÇøÁÆ°ÁêÜ")
    st.caption("Ë§áÊï∞„Éï„Ç°„Ç§„É´„Å´ÂÖ±ÈÄö„ÅÆÊÉÖÂ†±„ÇíÂäπÁéáÁöÑ„Å´Ë®≠ÂÆö„Åß„Åç„Åæ„Åô")
    
    # „Éï„Ç°„Ç§„É´‰∏ÄË¶ßÂèñÂæó
    files = get_file_list(chroma_client)
    
    if not files:
        st.info("„Éï„Ç°„Ç§„É´„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        return
    
    st.write("**„Éï„Ç°„Ç§„É´ÈÅ∏Êäû:**")
    
    # ÂÖ®ÈÅ∏Êäû„ÉÅ„Çß„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„Çπ
    select_all = st.checkbox("‚òëÔ∏è ÂÖ®„Å¶ÈÅ∏Êäû", value=False, key="select_all_bulk")
    
    # „Éï„Ç°„Ç§„É´ÈÅ∏Êäû
    selected_files = []
    for file_name, info in sorted(files.items()):
        default_checked = select_all
        if st.checkbox(
            f"üìÑ {file_name} ({info['page_count']}„Éö„Éº„Ç∏ / {info['chunk_count']}„ÉÅ„É£„É≥„ÇØ)",
            value=default_checked,
            key=f"bulk_select_{file_name}"
        ):
            selected_files.append(file_name)
    
    if not selected_files:
        st.info("üëÜ „Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
        return
    
    st.markdown("---")
    
    # ÈÅ∏Êäû„Éï„Ç°„Ç§„É´„ÅÆÁµ±Ë®à
    total_chunks = sum(files[f]["chunk_count"] for f in selected_files)
    st.info(f"üìä ÈÅ∏Êäû: {len(selected_files)}„Éï„Ç°„Ç§„É´ / {total_chunks}„ÉÅ„É£„É≥„ÇØ")
    
    st.write("**ÂÖ±ÈÄö„É°„Çø„Éá„Éº„Çø:**")
    
    # ÂÖ±ÈÄö„É°„Çø„Éá„Éº„ÇøÂÖ•Âäõ
    col1, col2 = st.columns(2)
    
    with col1:
        common_product = st.text_input(
            "Ë£ΩÂìÅÁ®ÆÂà•",
            key="bulk_product",
            help="ÂÖ®ÈÅ∏Êäû„Éï„Ç°„Ç§„É´„Å´ÈÅ©Áî®"
        )
        
        common_manufacturer = st.text_input(
            "„É°„Éº„Ç´„Éº",
            key="bulk_manufacturer"
        )
        
        common_category = st.text_input(
            "„Ç´„ÉÜ„Ç¥„É™",
            key="bulk_category"
        )
    
    with col2:
        common_tags = st.text_input(
            "„Çø„Ç∞Ôºà„Ç´„É≥„ÉûÂå∫Âàá„ÇäÔºâ",
            key="bulk_tags"
        )
        
        common_notes = st.text_area(
            "ÂÇôËÄÉ„Éª„É°„É¢",
            key="bulk_notes",
            height=100
        )
    
    # ÂÖ±ÈÄö„É°„Çø„Éá„Éº„Çø„ÇíÊßãÁØâ
    common_metadata = {}
    if common_product:
        common_metadata["product_type"] = common_product
    if common_manufacturer:
        common_metadata["manufacturer"] = common_manufacturer
    if common_category:
        common_metadata["category"] = common_category
    if common_tags:
        common_metadata["tags"] = common_tags
    if common_notes:
        common_metadata["notes"] = common_notes
    
    # „Éó„É¨„Éì„É•„Éº
    if common_metadata:
        st.markdown("---")
        st.write("**üìã „Éó„É¨„Éì„É•„ÉºÔºàÊõ¥Êñ∞ÂÜÖÂÆπÔºâ:**")
        
        try:
            preview = preview_bulk_update(chroma_client, selected_files, common_metadata)
            
            for item in preview:
                if item["changes"]:
                    with st.expander(f"üìÑ {item['file_name']} ({item['chunk_count']}„ÉÅ„É£„É≥„ÇØ)"):
                        for field, change in item["changes"].items():
                            old_val = change["old"] if change["old"] else "(Á©∫)"
                            new_val = change["new"] if change["new"] else "(Á©∫)"
                            st.write(f"**{field}:** `{old_val}` ‚Üí `{new_val}`")
        
        except Exception as e:
            st.error(f"„Éó„É¨„Éì„É•„ÉºÁîüÊàê„Ç®„É©„Éº: {e}")
        
        st.markdown("---")
        
        # ‰∏ÄÊã¨ÈÅ©Áî®„Éú„Çø„É≥
        col_apply1, col_apply2 = st.columns([2, 1])
        
        with col_apply1:
            if st.button(
                f"üíæ {len(selected_files)}„Éï„Ç°„Ç§„É´„Å´‰∏ÄÊã¨ÈÅ©Áî®Ôºà{total_chunks}„ÉÅ„É£„É≥„ÇØÔºâ",
                type="primary",
                use_container_width=True
            ):
                try:
                    with st.spinner("Êõ¥Êñ∞‰∏≠..."):
                        result = bulk_update_metadata(chroma_client, selected_files, common_metadata)
                    
                    st.success(f"‚úÖ ÊàêÂäü: {result['total_updated']}„ÉÅ„É£„É≥„ÇØ„ÇíÊõ¥Êñ∞„Åó„Åæ„Åó„Åü")
                    
                    # Ë©≥Á¥∞Ë°®Á§∫
                    with st.expander("üìä Êõ¥Êñ∞Ë©≥Á¥∞"):
                        for file_name, count in result["files"].items():
                            st.write(f"‚Ä¢ {file_name}: {count}„ÉÅ„É£„É≥„ÇØ")
                    
                    st.balloons()
                    
                    import time
                    time.sleep(2)
                    st.rerun()
                
                except Exception as e:
                    st.error(f"‚ùå ‰∏ÄÊã¨Êõ¥Êñ∞Â§±Êïó: {e}")
                    logger.error(f"Bulk update failed: {e}")
        
        with col_apply2:
            if st.button("üîÑ „É™„Çª„ÉÉ„Éà", use_container_width=True):
                st.rerun()
    else:
        st.info("üëÜ ÂÖ±ÈÄö„É°„Çø„Éá„Éº„Çø„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ")


def render_by_file(grouped_docs, image_cache):
    """„Éï„Ç°„Ç§„É´Âà•Ë°®Á§∫"""
    st.subheader("üìÅ „Éï„Ç°„Ç§„É´Âà•Ë°®Á§∫")
    
    file_names = sorted(grouped_docs.keys())
    selected_file = st.selectbox("„Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû", file_names)
    
    if selected_file:
        docs = grouped_docs[selected_file]
        
        # „Éö„Éº„Ç∏„Åî„Å®„Å´„Ç∞„É´„Éº„ÉóÂåñ
        pages = {}
        for doc in docs:
            page_num = doc['metadata'].get('page', 0)
            if page_num not in pages:
                pages[page_num] = []
            pages[page_num].append(doc)
        
        total_chunks = len(docs)
        total_pages = len(pages)
        st.info(f"üìÑ {selected_file}: {total_pages}„Éö„Éº„Ç∏Ôºà{total_chunks}„ÉÅ„É£„É≥„ÇØÔºâ")
        
        # „Éö„Éº„Ç∏ÈÅ∏Êäû
        page_numbers = sorted(pages.keys())
        selected_page = st.selectbox(
            "„Éö„Éº„Ç∏„ÇíÈÅ∏Êäû", 
            page_numbers,
            format_func=lambda x: f"„Éö„Éº„Ç∏ {x} ({len(pages[x])}„ÉÅ„É£„É≥„ÇØ)"
        )
        
        page_docs = pages[selected_page]
        
        # „ÉÅ„É£„É≥„ÇØ„ÅåË§áÊï∞„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÉÅ„É£„É≥„ÇØÈÅ∏Êäû
        if len(page_docs) > 1:
            st.caption(f"„Åì„ÅÆ„Éö„Éº„Ç∏„Å´„ÅØ{len(page_docs)}ÂÄã„ÅÆ„ÉÅ„É£„É≥„ÇØ„Åå„ÅÇ„Çä„Åæ„Åô")
            selected_chunk_idx = st.selectbox(
                "„ÉÅ„É£„É≥„ÇØ„ÇíÈÅ∏Êäû",
                range(len(page_docs)),
                format_func=lambda x: f"„ÉÅ„É£„É≥„ÇØ {x+1}/{len(page_docs)} ({len(page_docs[x]['text'])}ÊñáÂ≠ó)"
            )
            doc = page_docs[selected_chunk_idx]
        else:
            doc = page_docs[0]
        
        render_document_detail(doc, image_cache)


def render_all_pages(documents, image_cache):
    """ÂÖ®„Éö„Éº„Ç∏‰∏ÄË¶ßË°®Á§∫"""
    st.subheader("üìÑ ÂÖ®„Éö„Éº„Ç∏‰∏ÄË¶ß")
    
    items_per_page = st.slider("1„Éö„Éº„Ç∏„ÅÇ„Åü„Çä„ÅÆË°®Á§∫‰ª∂Êï∞", 1, 20, 5)
    total_pages = (len(documents) - 1) // items_per_page + 1
    current_page = st.number_input("„Éö„Éº„Ç∏", 1, total_pages, 1)
    
    start_idx = (current_page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, len(documents))
    
    st.caption(f"ÂÖ®{len(documents)}‰ª∂‰∏≠ {start_idx + 1}-{end_idx}‰ª∂„ÇíË°®Á§∫")
    
    for idx in range(start_idx, end_idx):
        doc = documents[idx]
        with st.expander(
            f"üìÑ {doc['metadata'].get('file_name', 'Unknown')} - "
            f"„Éö„Éº„Ç∏ {doc['metadata'].get('page', '?')} "
            f"({'üñºÔ∏è' if doc['metadata'].get('num_images', 0) > 0 else 'üìù'})",
            expanded=False
        ):
            render_document_detail(doc, image_cache)
        st.markdown("---")


def render_with_images_only(documents, image_cache):
    """ÁîªÂÉè‰ªò„Åç„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ„ÅøË°®Á§∫"""
    st.subheader("üñºÔ∏è ÁîªÂÉè‰ªò„Åç„Éâ„Ç≠„É•„É°„É≥„Éà")
    
    docs_with_images = [doc for doc in documents if doc['metadata'].get('num_images', 0) > 0]
    
    if not docs_with_images:
        st.warning("ÁîªÂÉè‰ªò„Åç„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        return
    
    st.info(f"ÂÖ®{len(documents)}‰ª∂‰∏≠„ÄÅ{len(docs_with_images)}‰ª∂„ÅåÁîªÂÉè‰ªò„Åç")
    
    items_per_page = st.slider("1„Éö„Éº„Ç∏„ÅÇ„Åü„Çä„ÅÆË°®Á§∫‰ª∂Êï∞", 1, 10, 3)
    total_pages = (len(docs_with_images) - 1) // items_per_page + 1
    current_page = st.number_input("„Éö„Éº„Ç∏", 1, total_pages, 1)
    
    start_idx = (current_page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, len(docs_with_images))
    
    for idx in range(start_idx, end_idx):
        doc = docs_with_images[idx]
        with st.expander(
            f"üìÑ {doc['metadata'].get('file_name', 'Unknown')} - "
            f"„Éö„Éº„Ç∏ {doc['metadata'].get('page', '?')} "
            f"({doc['metadata'].get('num_images', 0)}Êûö„ÅÆÁîªÂÉè)",
            expanded=True
        ):
            render_document_detail(doc, image_cache)
        st.markdown("---")


def render_document_detail(doc, image_cache):
    """„Éâ„Ç≠„É•„É°„É≥„ÉàË©≥Á¥∞Ë°®Á§∫"""
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üìù „ÉÜ„Ç≠„Çπ„ÉàÂÜÖÂÆπ")
        
        metadata = doc['metadata']
        st.markdown(f"**„Éï„Ç°„Ç§„É´Âêç:** {metadata.get('file_name', 'Unknown')}")
        st.markdown(f"**„Éö„Éº„Ç∏:** {metadata.get('page', '?')} / {metadata.get('total_pages', '?')}")
        st.markdown(f"**ÁîªÂÉèÊï∞:** {metadata.get('num_images', 0)}Êûö")
        st.markdown(f"**ÊñáÂ≠óÊï∞:** {len(doc['text'])}ÊñáÂ≠ó")
        
        with st.container():
            st.text_area(
                "ÂÜÖÂÆπ",
                doc['text'],
                height=200,
                key=f"text_{doc['id']}"
            )
    
    with col2:
        st.markdown("### üî¢ „É°„Çø„Éá„Éº„Çø")
        st.json(metadata)
    
    # ÁîªÂÉèË°®Á§∫
    if metadata.get('num_images', 0) > 0:
        st.markdown("---")
        st.markdown("### üñºÔ∏è Èñ¢ÈÄ£ÁîªÂÉè")
        
        try:
            image_ids_str = metadata.get('image_ids', '[]')
            if isinstance(image_ids_str, str):
                image_ids = json.loads(image_ids_str)
            else:
                image_ids = image_ids_str
            
            if image_ids:
                cols = st.columns(min(3, len(image_ids)))
                
                for idx, image_id in enumerate(image_ids):
                    cached_data = image_cache.get_image(image_id)
                    
                    if cached_data:
                        with cols[idx % 3]:
                            st.image(
                                cached_data["image"],
                                caption=f"ÁîªÂÉè {idx + 1}: {image_id}",
                                use_container_width=True
                            )
                            
                            img_meta = cached_data["metadata"]
                            st.caption(f"„Éö„Éº„Ç∏: {img_meta.get('page')}")
                            st.caption(f"„Çø„Ç§„Éó: {img_meta.get('type')}")
                    else:
                        with cols[idx % 3]:
                            st.error(f"‚ùå ÁîªÂÉè„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì: {image_id}")
            else:
                st.info("ÁîªÂÉèID„ÅåË®òÈå≤„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì")
        
        except json.JSONDecodeError as e:
            st.error(f"ÁîªÂÉèIDËß£Êûê„Ç®„É©„Éº: {e}")
        except Exception as e:
            st.error(f"ÁîªÂÉèË°®Á§∫„Ç®„É©„Éº: {e}")
    
    # „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±
    with st.expander("üîß „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±"):
        st.markdown(f"**Document ID:** `{doc['id']}`")
        st.markdown(f"**EmbeddingÊ¨°ÂÖÉÊï∞:** {doc['embedding_size']}")
        
        if 'image_ids' in metadata:
            st.markdown("**Image IDs (Raw):**")
            st.code(metadata['image_ids'])


def export_vectordb_summary(documents):
    """
    VectorDBÂÜÖÂÆπ„Çí„Ç®„ÇØ„Çπ„Éù„Éº„Éà
    """
    st.subheader("üì• „Éá„Éº„Çø„Ç®„ÇØ„Çπ„Éù„Éº„Éà")
    
    summary = []
    for doc in documents:
        summary.append({
            "file_name": doc['metadata'].get('file_name'),
            "page": doc['metadata'].get('page'),
            "text_length": len(doc['text']),
            "num_images": doc['metadata'].get('num_images', 0),
            "text_preview": doc['text'][:100] + "..." if len(doc['text']) > 100 else doc['text']
        })
    
    import json
    json_str = json.dumps(summary, ensure_ascii=False, indent=2)
    
    st.download_button(
        label="üì• JSONÂΩ¢Âºè„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        data=json_str,
        file_name="vectordb_summary.json",
        mime="application/json"
    )
    
    import csv
    import io
    
    csv_buffer = io.StringIO()
    csv_writer = csv.DictWriter(csv_buffer, fieldnames=summary[0].keys())
    csv_writer.writeheader()
    csv_writer.writerows(summary)
    
    st.download_button(
        label="üì• CSVÂΩ¢Âºè„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        data=csv_buffer.getvalue(),
        file_name="vectordb_summary.csv",
        mime="text/csv"
    )