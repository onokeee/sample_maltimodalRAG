"""
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - æ”¹å–„ç‰ˆ
å„ªå…ˆåº¦:é«˜ã®æ”¹å–„ã‚’å…¨ã¦åæ˜ 
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
- ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ãƒ¡ãƒ¢ãƒªç®¡ç†æ”¹å–„
"""
import streamlit as st
import chromadb
import os
import shutil
import json
from pathlib import Path
from dotenv import load_dotenv

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from core.rag_engine import initialize_rag_system, load_and_index_documents, query_index
from core.image_handler import ImageCache
from utils.logger import get_logger
from utils.exceptions import (
    APIKeyError, FileUploadError, IndexCreationError, 
    QueryError, PDFProcessingError
)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = get_logger()
logger.info("=" * 50)
logger.info("Application started")
logger.info("=" * 50)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.0",
    page_icon="ğŸ”",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "index_created" not in st.session_state:
    st.session_state.index_created = False
if "image_cache" not in st.session_state:
    st.session_state.image_cache = ImageCache()
if "use_multimodal" not in st.session_state:
    st.session_state.use_multimodal = False


@st.cache_resource
def get_chroma_client():
    """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—"""
    try:
        client = chromadb.PersistentClient(path="./chroma_db")
        logger.info("ChromaDB client initialized")
        return client
    except Exception as e:
        logger.error(f"Failed to initialize ChromaDB: {e}")
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


def validate_api_key(api_key):
    """APIã‚­ãƒ¼ã®æ¤œè¨¼"""
    if not api_key:
        raise APIKeyError("APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    if not api_key.startswith("sk-"):
        raise APIKeyError("ç„¡åŠ¹ãªAPIã‚­ãƒ¼å½¢å¼ã§ã™ï¼ˆsk-ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰")
    
    if len(api_key) < 20:
        raise APIKeyError("APIã‚­ãƒ¼ãŒçŸ­ã™ãã¾ã™")
    
    logger.info("API key validated successfully")
    return True


def validate_file_upload(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ100MBï¼‰
    max_size_mb = 100
    file_size_mb = uploaded_file.size / (1024 * 1024)
    
    if file_size_mb > max_size_mb:
        raise FileUploadError(
            f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {file_size_mb:.1f}MBï¼ˆä¸Šé™: {max_size_mb}MBï¼‰"
        )
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—æ¤œè¨¼
    allowed_types = ['.txt', '.pdf', '.md']
    file_ext = Path(uploaded_file.name).suffix.lower()
    
    if file_ext not in allowed_types:
        raise FileUploadError(
            f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_ext}ï¼ˆå¯¾å¿œå½¢å¼: {', '.join(allowed_types)}ï¼‰"
        )
    
    logger.info(f"File upload validated: {uploaded_file.name} ({file_size_mb:.1f}MB)")
    return True


def get_images_from_node(node):
    """Nodeã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’å–å¾—"""
    images = []
    image_cache = st.session_state.image_cache
    
    try:
        if hasattr(node, 'metadata') and 'image_ids' in node.metadata:
            image_ids_str = node.metadata['image_ids']
            
            if isinstance(image_ids_str, str):
                image_ids = json.loads(image_ids_str)
            else:
                image_ids = image_ids_str
            
            for image_id in image_ids:
                cached_data = image_cache.get_image(image_id)
                if cached_data:
                    images.append({
                        **cached_data["metadata"],
                        "image": cached_data["image"]
                    })
    except (json.JSONDecodeError, TypeError) as e:
        logger.warning(f"Failed to parse image IDs: {e}")
    except Exception as e:
        logger.error(f"Error getting images from node: {e}")
    
    return images


# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.0")
st.caption("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ– | ä¸¦åˆ—å‡¦ç† | ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # APIã‚­ãƒ¼è¨­å®š
    api_key_input = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    if api_key_input:
        try:
            validate_api_key(api_key_input)
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")
            logger.info("API key configured")
        except APIKeyError as e:
            st.error(f"âŒ {str(e)}")
            logger.warning(f"Invalid API key: {e}")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    # ç”»åƒæŠ½å‡ºè¨­å®š
    st.subheader("ğŸ¨ ç”»åƒæŠ½å‡ºè¨­å®š")
    
    extraction_method = st.selectbox(
        "æŠ½å‡ºæ–¹æ³•",
        options=["high_quality", "medium_quality", "embedded", "combined"],
        format_func=lambda x: {
            "high_quality": "é«˜å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "medium_quality": "ä¸­å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "embedded": "åŸ‹ã‚è¾¼ã¿ç”»åƒï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰",
            "combined": "å…¨ã¦ï¼ˆãƒšãƒ¼ã‚¸+åŸ‹ã‚è¾¼ã¿ï¼‰"
        }[x],
        index=0
    )
    
    if extraction_method in ["high_quality", "medium_quality", "combined"]:
        dpi = st.slider("è§£åƒåº¦ï¼ˆDPIï¼‰", 72, 300, 200, 50)
    else:
        dpi = 150
    
    # ä¸¦åˆ—å‡¦ç†è¨­å®š
    max_workers = st.slider(
        "ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰æ•°",
        min_value=1,
        max_value=5,
        value=3,
        help="PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚’ä¸¦åˆ—åŒ–ã—ã¾ã™ï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰"
    )
    
    st.markdown("---")
    
    # æ¤œç´¢è¨­å®š
    st.subheader("ğŸ” æ¤œç´¢è¨­å®š")
    similarity_top_k = st.slider(
        "æ¤œç´¢çµæœä»¶æ•°",
        min_value=1,
        max_value=10,
        value=3,
        help="é¡ä¼¼åº¦ãŒé«˜ã„ä¸Šä½Nä»¶ã‚’å–å¾—"
    )
    
    st.markdown("---")
    
    # çµ±è¨ˆæƒ…å ±
    st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    data_dir = Path("./uploaded_data")
    if data_dir.exists():
        files = list(data_dir.glob("*.*"))
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", len(files))
    else:
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", 0)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±
    total_images = len(st.session_state.image_cache.registry)
    if total_images > 0:
        st.metric("ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥", total_images)
        cache_size_mb = st.session_state.image_cache.current_memory / (1024 * 1024)
        st.caption(f"ä½¿ç”¨é‡: {cache_size_mb:.1f}MB")
    
    if st.session_state.index_created:
        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ¸ˆã¿")
    else:
        st.info("â„¹ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ")
    
    st.markdown("---")
    
    # è¡¨ç¤ºè¨­å®š
    st.subheader("ğŸ‘ï¸ è¡¨ç¤ºè¨­å®š")
    show_images_in_chat = st.checkbox("ãƒãƒ£ãƒƒãƒˆã«ç”»åƒã‚’è¡¨ç¤º", value=True)
    show_sources = st.checkbox("å‚ç…§å…ƒã‚’è¡¨ç¤º", value=True)
    
    st.markdown("---")
    
    # ãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", type="secondary"):
        if st.session_state.get("confirm_reset", False):
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                if data_dir.exists():
                    shutil.rmtree(data_dir)
                    data_dir.mkdir()
                
                # DBå‰Šé™¤
                chroma_dir = Path("./chroma_db")
                if chroma_dir.exists():
                    shutil.rmtree(chroma_dir)
                    chroma_dir.mkdir()
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
                st.session_state.image_cache.clear()
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
                st.session_state.index_created = False
                st.session_state.messages = []
                st.cache_resource.clear()
                
                st.success("âœ… ãƒªã‚»ãƒƒãƒˆå®Œäº†")
                logger.info("All data reset successfully")
                st.session_state.confirm_reset = False
                st.rerun()
            except Exception as e:
                st.error(f"âŒ ãƒªã‚»ãƒƒãƒˆå¤±æ•—: {e}")
                logger.error(f"Reset failed: {e}")
        else:
            st.session_state.confirm_reset = True
            st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèª")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not api_key_input:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

tab1, tab2, tab3 = st.tabs(["ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†", "ğŸ’¬ è³ªå•å¿œç­”", "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"])

with tab1:
    st.header("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
            accept_multiple_files=True,
            type=["txt", "pdf", "md"],
            help="å¯¾å¿œå½¢å¼: .txt, .pdf, .mdï¼ˆæœ€å¤§100MB/ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"
        )
        
        if uploaded_files:
            data_dir = Path("./uploaded_data")
            data_dir.mkdir(exist_ok=True)
            
            success_count = 0
            error_count = 0
            
            for uploaded_file in uploaded_files:
                try:
                    # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
                    validate_file_upload(uploaded_file)
                    
                    # ä¿å­˜
                    file_path = data_dir / uploaded_file.name
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    success_count += 1
                    logger.info(f"File uploaded: {uploaded_file.name}")
                
                except FileUploadError as e:
                    st.error(f"âŒ {uploaded_file.name}: {str(e)}")
                    error_count += 1
                    logger.warning(f"File upload failed: {uploaded_file.name} - {e}")
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ - {str(e)}")
                    error_count += 1
                    logger.error(f"Unexpected error during upload: {e}")
            
            if success_count > 0:
                st.success(f"âœ… {success_count}ä»¶ä¿å­˜å®Œäº†")
            if error_count > 0:
                st.warning(f"âš ï¸ {error_count}ä»¶å¤±æ•—")
    
    with col2:
        st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            files = sorted(data_dir.glob("*.*"))
            if files:
                for file in files:
                    size_kb = file.stat().st_size / 1024
                    icon = "ğŸ“„" if file.suffix.lower() == ".pdf" else "ğŸ“"
                    st.text(f"{icon} {file.name} ({size_kb:.1f}KB)")
            else:
                st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        else:
            st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    st.markdown("---")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    if st.button("ğŸ”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ", type="primary", use_container_width=True):
        data_dir = Path("./uploaded_data")
        
        if not data_dir.exists() or not list(data_dir.glob("*.*")):
            st.error("âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            logger.warning("No files to index")
        else:
            try:
                with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­..."):
                    chroma_client = get_chroma_client()
                    
                    if chroma_client is None:
                        raise IndexCreationError("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
                    storage_context = initialize_rag_system(chroma_client)
                    
                    index, error = load_and_index_documents(
                        str(data_dir),
                        storage_context,
                        extraction_method,
                        dpi,
                        max_workers=max_workers
                    )
                    
                    if error:
                        raise IndexCreationError(error)
                    
                    st.session_state.index = index
                    st.session_state.index_created = True
                    st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")
                    st.balloons()
                    logger.info("Index created successfully")
            
            except IndexCreationError as e:
                st.error(f"âŒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"Index creation failed: {e}")
            except PDFProcessingError as e:
                st.error(f"âŒ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"PDF processing failed: {e}")
            except Exception as e:
                st.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"Unexpected error during indexing: {e}", exc_info=True)
                with st.expander("è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±"):
                    st.code(str(e))

with tab2:
    st.header("ğŸ’¬ è³ªå•å¿œç­”")
    
    if not st.session_state.index_created:
        st.warning("âš ï¸ ã¾ãšã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
    else:
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # ç”»åƒè¡¨ç¤º
                if (message["role"] == "assistant" and 
                    "images" in message and 
                    message["images"] and 
                    show_images_in_chat):
                    st.markdown("---")
                    st.markdown("**ğŸ“¸ é–¢é€£ç”»åƒ:**")
                    cols = st.columns(min(3, len(message["images"])))
                    for idx, img_data in enumerate(message["images"][:6]):
                        with cols[idx % 3]:
                            caption = f"{img_data.get('file_name', 'Unknown')} - Page {img_data.get('page', '?')}"
                            st.image(img_data["image"], caption=caption, use_container_width=True)
                
                # å‚ç…§å…ƒè¡¨ç¤º
                if show_sources and "sources" in message and message["sources"]:
                    with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                        for i, source in enumerate(message["sources"]):
                            st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source.get('file_name', 'Unknown')} (Page {source.get('page', '?')})")
                            st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                            st.text(source["text"][:200] + "...")
                            st.divider()
        
        # è³ªå•å…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”
            with st.chat_message("assistant"):
                try:
                    with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
                        response = query_index(
                            st.session_state.index,
                            prompt,
                            similarity_top_k=similarity_top_k
                        )
                        
                        st.markdown(response.response)
                        
                        # ã‚½ãƒ¼ã‚¹æƒ…å ±åé›†
                        sources = []
                        all_images = []
                        
                        for node in response.source_nodes:
                            sources.append({
                                "text": node.text,
                                "score": node.score,
                                "file_name": node.metadata.get("file_name", "Unknown"),
                                "page": node.metadata.get("page", "?")
                            })
                            
                            # ç”»åƒå–å¾—
                            node_images = get_images_from_node(node)
                            all_images.extend(node_images)
                        
                        # é‡è¤‡å‰Šé™¤
                        seen = set()
                        unique_images = []
                        for img in all_images:
                            key = (img.get('file_name'), img.get('page'), img.get('type'))
                            if key not in seen:
                                seen.add(key)
                                unique_images.append(img)
                        
                        # ç”»åƒè¡¨ç¤º
                        if unique_images and show_images_in_chat:
                            st.markdown("---")
                            st.markdown("**ğŸ“¸ é–¢é€£ç”»åƒ:**")
                            cols = st.columns(min(3, len(unique_images)))
                            for idx, img_data in enumerate(unique_images[:6]):
                                with cols[idx % 3]:
                                    caption = f"{img_data.get('file_name', 'Unknown')} - Page {img_data.get('page', '?')}"
                                    st.image(img_data["image"], caption=caption, use_container_width=True)
                        
                        # å‚ç…§å…ƒè¡¨ç¤º
                        if show_sources and sources:
                            with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                                for i, source in enumerate(sources):
                                    st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source['file_name']} (Page {source['page']})")
                                    st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                                    st.text(source["text"][:200] + "...")
                                    st.divider()
                        
                        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response.response,
                            "sources": sources,
                            "images": unique_images
                        })
                        
                        logger.info(f"Query answered: {prompt[:50]}...")
                
                except QueryError as e:
                    error_msg = f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    logger.error(f"Query error: {e}")
                except Exception as e:
                    error_msg = f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})
                    logger.error(f"Unexpected error during query: {e}", exc_info=True)

with tab3:
    st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ’¾ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            total_size = sum(f.stat().st_size for f in data_dir.glob("*.*"))
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º", f"{total_size / (1024*1024):.1f} MB")
        
        # ChromaDB
        chroma_dir = Path("./chroma_db")
        if chroma_dir.exists():
            chroma_size = sum(f.stat().st_size for f in chroma_dir.rglob("*") if f.is_file())
            st.metric("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º", f"{chroma_size / (1024*1024):.1f} MB")
        
        # ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥
        cache_dir = Path("./image_cache")
        if cache_dir.exists():
            cache_size = sum(f.stat().st_size for f in cache_dir.glob("*") if f.is_file())
            st.metric("ç”»åƒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º", f"{cache_size / (1024*1024):.1f} MB")
    
    with col2:
        st.subheader("ğŸ“ˆ ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹")
        st.metric("ãƒãƒ£ãƒƒãƒˆå±¥æ­´", len(st.session_state.messages))
        st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”»åƒæ•°", len(st.session_state.image_cache.registry))
        
        if st.session_state.index_created:
            st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: ä½œæˆæ¸ˆã¿")
        else:
            st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: æœªä½œæˆ")
    
    st.markdown("---")
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
    st.subheader("ğŸ“ æœ€æ–°ãƒ­ã‚°")
    log_dir = Path("./logs")
    if log_dir.exists():
        log_files = sorted(log_dir.glob("*.log"), key=lambda x: x.stat().st_mtime, reverse=True)
        if log_files:
            latest_log = log_files[0]
            with open(latest_log, 'r', encoding='utf-8') as f:
                log_content = f.readlines()
            
            st.text(f"ãƒ•ã‚¡ã‚¤ãƒ«: {latest_log.name}")
            st.code("".join(log_content[-20:]), language="log")  # æœ€æ–°20è¡Œ
        else:
            st.info("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.0 | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ– | ä¸¦åˆ—å‡¦ç† | ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
    </div>
    """,
    unsafe_allow_html=True
)
