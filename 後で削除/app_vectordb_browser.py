"""
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ - æ”¹å–„ç‰ˆ v2.2
ğŸ†• VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼è¿½åŠ 
"""
import streamlit as st
import chromadb
import os
import shutil
import json
from pathlib import Path
from dotenv import load_dotenv

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from core.rag_engine import initialize_rag_system, load_and_index_documents, query_index
from core.image_handler import ImageCache
from core.multimodal_query import query_with_multimodal, render_response_with_images
from core.vectordb_browser import render_vectordb_browser, export_vectordb_summary, get_all_documents_from_vectordb
from utils.logger import get_logger
from utils.exceptions import (
    APIKeyError, FileUploadError, IndexCreationError, 
    QueryError, PDFProcessingError
)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
logger = get_logger()
logger.info("=" * 50)
logger.info("Application started - VectorDB Browser v2.2")
logger.info("=" * 50)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.2",
    page_icon="ğŸ”",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "index_created" not in st.session_state:
    st.session_state.index_created = False
if "image_cache" not in st.session_state:
    st.session_state.image_cache = ImageCache()
if "use_multimodal" not in st.session_state:
    st.session_state.use_multimodal = True


@st.cache_resource
def get_chroma_client():
    """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—"""
    try:
        client = chromadb.PersistentClient(path="./chroma_db")
        logger.info("ChromaDB client initialized")
        return client
    except Exception as e:
        logger.error(f"Failed to initialize ChromaDB: {e}")
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None


def validate_api_key(api_key):
    """APIã‚­ãƒ¼ã®æ¤œè¨¼"""
    if not api_key:
        raise APIKeyError("APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    if not api_key.startswith("sk-"):
        raise APIKeyError("ç„¡åŠ¹ãªAPIã‚­ãƒ¼å½¢å¼ã§ã™ï¼ˆsk-ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰")
    
    if len(api_key) < 20:
        raise APIKeyError("APIã‚­ãƒ¼ãŒçŸ­ã™ãã¾ã™")
    
    logger.info("API key validated successfully")
    return True


def validate_file_upload(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
    max_size_mb = 100
    file_size_mb = uploaded_file.size / (1024 * 1024)
    
    if file_size_mb > max_size_mb:
        raise FileUploadError(
            f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™: {file_size_mb:.1f}MBï¼ˆä¸Šé™: {max_size_mb}MBï¼‰"
        )
    
    allowed_types = ['.txt', '.pdf', '.md']
    file_ext = Path(uploaded_file.name).suffix.lower()
    
    if file_ext not in allowed_types:
        raise FileUploadError(
            f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_ext}ï¼ˆå¯¾å¿œå½¢å¼: {', '.join(allowed_types)}ï¼‰"
        )
    
    logger.info(f"File upload validated: {uploaded_file.name} ({file_size_mb:.1f}MB)")
    return True


def get_images_from_node(node):
    """Nodeã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’å–å¾—"""
    images = []
    image_cache = st.session_state.image_cache
    
    try:
        if hasattr(node, 'metadata') and 'image_ids' in node.metadata:
            image_ids_str = node.metadata['image_ids']
            
            if isinstance(image_ids_str, str):
                image_ids = json.loads(image_ids_str)
            else:
                image_ids = image_ids_str
            
            for image_id in image_ids:
                cached_data = image_cache.get_image(image_id)
                if cached_data:
                    images.append({
                        **cached_data["metadata"],
                        "image": cached_data["image"]
                    })
    except (json.JSONDecodeError, TypeError) as e:
        logger.warning(f"Failed to parse image IDs: {e}")
    except Exception as e:
        logger.error(f"Error getting images from node: {e}")
    
    return images


# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.2")
st.caption("ğŸ†• VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼è¿½åŠ  | æ–‡ç« ä¸­ã«ç”»åƒåŸ‹ã‚è¾¼ã¿ | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆçœç•¥ - å‰ã¨åŒã˜ï¼‰
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    api_key_input = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    if api_key_input:
        try:
            validate_api_key(api_key_input)
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")
        except APIKeyError as e:
            st.error(f"âŒ {str(e)}")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    st.subheader("ğŸ¤– å›ç­”ãƒ¢ãƒ¼ãƒ‰")
    use_multimodal = st.checkbox(
        "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ¼ãƒ‰",
        value=st.session_state.use_multimodal
    )
    st.session_state.use_multimodal = use_multimodal
    
    st.markdown("---")
    
    st.subheader("ğŸ¨ ç”»åƒæŠ½å‡ºè¨­å®š")
    extraction_method = st.selectbox(
        "æŠ½å‡ºæ–¹æ³•",
        options=["high_quality", "medium_quality", "embedded", "combined"],
        format_func=lambda x: {
            "high_quality": "é«˜å“è³ª", "medium_quality": "ä¸­å“è³ª",
            "embedded": "åŸ‹ã‚è¾¼ã¿", "combined": "å…¨ã¦"
        }[x]
    )
    
    if extraction_method in ["high_quality", "medium_quality", "combined"]:
        dpi = st.slider("DPI", 72, 300, 200, 50)
    else:
        dpi = 150
    
    max_workers = st.slider("ä¸¦åˆ—å‡¦ç†", 1, 5, 3)
    
    st.markdown("---")
    
    st.subheader("ğŸ” æ¤œç´¢è¨­å®š")
    similarity_top_k = st.slider("æ¤œç´¢çµæœä»¶æ•°", 1, 10, 3)
    
    st.markdown("---")
    
    st.subheader("ğŸ“Š çµ±è¨ˆ")
    data_dir = Path("./uploaded_data")
    if data_dir.exists():
        files = list(data_dir.glob("*.*"))
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", len(files))
    
    total_images = len(st.session_state.image_cache.registry)
    if total_images > 0:
        st.metric("ç”»åƒ", total_images)
    
    if st.session_state.index_created:
        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ¸ˆã¿")
    else:
        st.info("â„¹ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ")
    
    st.markdown("---")
    
    show_sources = st.checkbox("å‚ç…§å…ƒã‚’è¡¨ç¤º", value=True)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not api_key_input:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

# ğŸ†• ã‚¿ãƒ–ã‚’4ã¤ã«å¢—ã‚„ã™
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†", 
    "ğŸ’¬ è³ªå•å¿œç­”", 
    "ğŸ” VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼",  # ğŸ†• æ–°ã—ã„ã‚¿ãƒ–
    "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"
])

# ã‚¿ãƒ–1: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†ï¼ˆçœç•¥ - app_multimodal.pyã¨åŒã˜ï¼‰
with tab1:
    st.header("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")
    # ... çœç•¥ï¼ˆå‰ã¨åŒã˜ï¼‰

# ã‚¿ãƒ–2: è³ªå•å¿œç­”ï¼ˆçœç•¥ - app_multimodal.pyã¨åŒã˜ï¼‰
with tab2:
    st.header("ğŸ’¬ è³ªå•å¿œç­”")
    # ... çœç•¥ï¼ˆå‰ã¨åŒã˜ï¼‰

# ğŸ†• ã‚¿ãƒ–3: VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼
with tab3:
    if not st.session_state.index_created:
        st.warning("âš ï¸ ã¾ãšã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
    else:
        chroma_client = get_chroma_client()
        if chroma_client:
            render_vectordb_browser(chroma_client, st.session_state.image_cache)
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
            st.markdown("---")
            documents = get_all_documents_from_vectordb(chroma_client)
            if documents:
                export_vectordb_summary(documents)

# ã‚¿ãƒ–4: ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ï¼ˆçœç•¥ - app_multimodal.pyã¨åŒã˜ï¼‰
with tab4:
    st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    # ... çœç•¥ï¼ˆå‰ã¨åŒã˜ï¼‰

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.2 | ğŸ†• VectorDBãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ | æ–‡ç« ä¸­ã«ç”»åƒåŸ‹ã‚è¾¼ã¿
    </div>
    """,
    unsafe_allow_html=True
)
