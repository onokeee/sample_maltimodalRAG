import streamlit as st
from llama_index.core import (
    VectorStoreIndex,
    StorageContext,
    Settings,
    Document
)
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
import chromadb
import os
from pathlib import Path
from dotenv import load_dotenv
import shutil
import pypdf
import pdfplumber
from PIL import Image
import io
import fitz
import base64
import json


# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ”",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "index_created" not in st.session_state:
    st.session_state.index_created = False
if "pdf_images" not in st.session_state:
    st.session_state.pdf_images = {}
if "image_registry" not in st.session_state:
    st.session_state.image_registry = {}  # image_id -> image_data
if "use_multimodal" not in st.session_state:
    st.session_state.use_multimodal = False

@st.cache_resource
def get_chroma_client():
    """ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—"""
    client = chromadb.PersistentClient(path="./chroma_db")
    return client

@st.cache_resource
def initialize_rag_system(_chroma_client, collection_name="multimodal_rag"):
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    try:
        _chroma_client.delete_collection(collection_name)
    except:
        pass
    
    chroma_collection = _chroma_client.create_collection(collection_name)
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    
    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¨LLMã®è¨­å®š
    Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")
    Settings.llm = OpenAI(model="gpt-4o-mini", temperature=0.1)
    
    return storage_context

def extract_images_high_quality(pdf_path, dpi=300):
    """ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’é«˜å“è³ªç”»åƒåŒ–"""
    images = []
    try:
        pdf_document = fitz.open(pdf_path)
        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]
            zoom = dpi / 72.0
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, alpha=False)
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))
            
            images.append({
                "page": page_num + 1,
                "image": image,
                "type": "full_page",
                "file_name": pdf_path.name
            })
        pdf_document.close()
    except Exception as e:
        st.warning(f"ãƒšãƒ¼ã‚¸ç”»åƒåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
    return images

def extract_images_embedded_positioned(pdf_path, min_size=100):
    """ğŸŒŸ ä½ç½®æƒ…å ±ãƒ™ãƒ¼ã‚¹ã§ç”»åƒã‚’æ­£ç¢ºã«åˆ‡ã‚ŠæŠœã"""
    images = []
    try:
        pdf_document = fitz.open(pdf_path)
        for page_num in range(len(pdf_document)):
            page = pdf_document[page_num]
            image_list = page.get_images(full=True)
            
            for img_index, img_info in enumerate(image_list):
                try:
                    xref = img_info[0]
                    rects = page.get_image_rects(xref)
                    
                    if not rects:
                        continue
                    
                    for rect_index, rect in enumerate(rects):
                        x0, y0, x1, y1 = rect
                        width = abs(x1 - x0)
                        height = abs(y1 - y0)
                        
                        if width < min_size or height < min_size:
                            continue
                        
                        aspect_ratio = width / height if height > 0 else 0
                        if aspect_ratio > 10 or aspect_ratio < 0.1:
                            continue
                        
                        mat = fitz.Matrix(2.0, 2.0)
                        clip_rect = fitz.Rect(x0, y0, x1, y1)
                        pix = page.get_pixmap(matrix=mat, clip=clip_rect, alpha=False)
                        img_data = pix.tobytes("png")
                        image = Image.open(io.BytesIO(img_data))
                        
                        if image.width < min_size or image.height < min_size:
                            continue
                        
                        images.append({
                            "page": page_num + 1,
                            "image": image,
                            "type": "embedded",
                            "file_name": pdf_path.name,
                            "index": img_index + 1,
                            "rect_index": rect_index + 1
                        })
                except:
                    continue
        pdf_document.close()
    except Exception as e:
        st.warning(f"åŸ‹ã‚è¾¼ã¿ç”»åƒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    return images

def extract_images_from_pdf(pdf_path, method="high_quality", dpi=300):
    """ç”»åƒæŠ½å‡ºã®çµ±åˆé–¢æ•°"""
    if method == "high_quality":
        return extract_images_high_quality(pdf_path, dpi=300)
    elif method == "medium_quality":
        return extract_images_high_quality(pdf_path, dpi=150)
    elif method == "embedded":
        return extract_images_embedded_positioned(pdf_path)
    elif method == "combined":
        page_images = extract_images_high_quality(pdf_path, dpi=200)
        embedded_images = extract_images_embedded_positioned(pdf_path)
        return page_images + embedded_images
    else:
        return extract_images_high_quality(pdf_path, dpi=300)

def extract_text_from_pdf(pdf_path):
    """PDFã‹ã‚‰ãƒšãƒ¼ã‚¸å˜ä½ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    page_texts = {}
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text()
                if page_text:
                    page_texts[page_num] = page_text
        
        if page_texts:
            return page_texts
        
        with open(pdf_path, 'rb') as file:
            pdf_reader = pypdf.PdfReader(file)
            for page_num, page in enumerate(pdf_reader.pages, 1):
                page_text = page.extract_text()
                if page_text:
                    page_texts[page_num] = page_text
        
        return page_texts
    except Exception as e:
        st.warning(f"PDFèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return {}

def register_images(images, file_name):
    """
    ğŸ†• ç”»åƒãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²ã—ã¦IDã‚’å‰²ã‚Šå½“ã¦
    """
    image_ids_by_page = {}
    
    for img_data in images:
        page_num = img_data["page"]
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªimage_idã‚’ç”Ÿæˆ
        image_id = f"{file_name}_p{page_num}_t{img_data['type']}"
        if "index" in img_data:
            image_id += f"_i{img_data['index']}"
        if "rect_index" in img_data:
            image_id += f"_r{img_data['rect_index']}"
        
        # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²
        st.session_state.image_registry[image_id] = img_data
        
        # ãƒšãƒ¼ã‚¸ã”ã¨ã®image_idãƒªã‚¹ãƒˆã‚’ä½œæˆ
        if page_num not in image_ids_by_page:
            image_ids_by_page[page_num] = []
        image_ids_by_page[page_num].append(image_id)
    
    return image_ids_by_page

def load_and_index_documents(data_dir, storage_context, extraction_method, dpi):
    """
    ğŸŒŸ æ”¹å–„ç‰ˆ: ãƒšãƒ¼ã‚¸å˜ä½ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
    """
    try:
        data_path = Path(data_dir)
        all_files = list(data_path.glob("*.*"))
        
        st.info(f"ğŸ“ æ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(all_files)}ä»¶")
        
        method_names = {
            "high_quality": f"é«˜å“è³ªãƒšãƒ¼ã‚¸å…¨ä½“ï¼ˆDPI {dpi}ï¼‰",
            "medium_quality": f"ä¸­å“è³ªãƒšãƒ¼ã‚¸å…¨ä½“ï¼ˆDPI {dpi}ï¼‰",
            "embedded": "ğŸŒŸ åŸ‹ã‚è¾¼ã¿ç”»åƒï¼ˆä½ç½®æƒ…å ±ãƒ™ãƒ¼ã‚¹ï¼‰",
            "combined": "ãƒšãƒ¼ã‚¸å…¨ä½“+åŸ‹ã‚è¾¼ã¿ç”»åƒ"
        }
        st.info(f"ğŸ¨ ç”»åƒæŠ½å‡ºæ–¹æ³•: {method_names.get(extraction_method, extraction_method)}")
        
        documents = []
        
        for file_path in all_files:
            if file_path.suffix.lower() == '.pdf':
                st.info(f"ğŸ“„ PDFã‚’å‡¦ç†ä¸­: {file_path.name}")
                
                # ãƒšãƒ¼ã‚¸å˜ä½ã§ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                page_texts = extract_text_from_pdf(file_path)
                
                # ç”»åƒæŠ½å‡º
                with st.spinner(f"ç”»åƒã‚’æŠ½å‡ºä¸­..."):
                    images = extract_images_from_pdf(file_path, method=extraction_method, dpi=dpi)
                
                if images:
                    st.session_state.pdf_images[file_path.name] = images
                    
                    # ğŸ†• ç”»åƒã‚’ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²
                    image_ids_by_page = register_images(images, file_path.name)
                    
                    st.success(f"ğŸ–¼ï¸ {len(images)}æšã®ç”»åƒã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                else:
                    image_ids_by_page = {}
                
                if page_texts:
                    # ğŸŒŸ ãƒšãƒ¼ã‚¸å˜ä½ã§Documentã‚’ä½œæˆï¼ˆé‡è¦ï¼ï¼‰
                    for page_num, page_text in page_texts.items():
                        # ã“ã®ãƒšãƒ¼ã‚¸ã®ç”»åƒIDãƒªã‚¹ãƒˆã‚’å–å¾—
                        page_image_ids = image_ids_by_page.get(page_num, [])
                        
                        # ğŸ”§ ãƒªã‚¹ãƒˆã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆChromaDBå¯¾å¿œï¼‰
                        image_ids_json = json.dumps(page_image_ids)
                        
                        doc = Document(
                            text=page_text,
                            metadata={
                                "file_name": file_path.name,
                                "page": page_num,
                                "total_pages": len(page_texts),
                                "image_ids": image_ids_json,  # ğŸ†• JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
                                "num_images": len(page_image_ids)
                            }
                        )
                        documents.append(doc)
                    
                    st.success(f"âœ… {len(page_texts)}ãƒšãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–")
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    with st.expander(f"ğŸ“„ {file_path.name} ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                        st.text(f"ç·ãƒšãƒ¼ã‚¸æ•°: {len(page_texts)}")
                        st.text(f"ç·ç”»åƒæ•°: {len(images)}")
                        
                        if images:
                            st.markdown("---")
                            st.markdown("**æŠ½å‡ºã•ã‚ŒãŸç”»åƒï¼ˆæœ€åˆã®6æšï¼‰:**")
                            cols = st.columns(3)
                            for idx, img_data in enumerate(images[:6]):
                                with cols[idx % 3]:
                                    caption = f"Page {img_data['page']} ({img_data['type']})"
                                    st.image(img_data["image"], caption=caption, use_container_width=True)
            
            elif file_path.suffix.lower() in ['.txt', '.md']:
                try:
                    encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp']
                    text = None
                    
                    for encoding in encodings:
                        try:
                            with open(file_path, 'r', encoding=encoding) as f:
                                text = f.read()
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if text:
                        doc = Document(
                            text=text,
                            metadata={
                                "file_name": file_path.name,
                                "file_type": file_path.suffix[1:]
                            }
                        )
                        documents.append(doc)
                except Exception as e:
                    st.warning(f"âš ï¸ {file_path.name}: {str(e)}")
        
        if not documents:
            return None, "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ"
        
        st.success(f"âœ… {len(documents)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ")
        
        with st.spinner("ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­..."):
            index = VectorStoreIndex.from_documents(
                documents,
                storage_context=storage_context,
                show_progress=True
            )
        
        return index, None
        
    except Exception as e:
        import traceback
        return None, f"ã‚¨ãƒ©ãƒ¼: {str(e)}\n\n{traceback.format_exc()}"

def get_images_from_node(node):
    """
    ğŸ†• Nodeã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’å–å¾—
    """
    images = []
    if hasattr(node, 'metadata') and 'image_ids' in node.metadata:
        # JSONæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            image_ids_str = node.metadata['image_ids']
            if isinstance(image_ids_str, str):
                image_ids = json.loads(image_ids_str)
            else:
                image_ids = image_ids_str  # æ—¢ã«ãƒªã‚¹ãƒˆã®å ´åˆ
            
            for image_id in image_ids:
                if image_id in st.session_state.image_registry:
                    images.append(st.session_state.image_registry[image_id])
        except (json.JSONDecodeError, TypeError) as e:
            st.warning(f"ç”»åƒIDè§£æã‚¨ãƒ©ãƒ¼: {e}")
    return images

def create_multimodal_prompt(query, context_text, context_images):
    """
    ğŸ†• ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    """
    prompt = f"""ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‘
{context_text}

ã€è³ªå•ã€‘
{query}

ã€å›ç­”ã€‘
"""
    return prompt

# ãƒ¡ã‚¤ãƒ³UI
st.title("ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ”¹å–„ç‰ˆï¼‰")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    api_key_input = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    if api_key_input:
        os.environ["OPENAI_API_KEY"] = api_key_input
        st.success("âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")
    else:
        st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    st.markdown("---")
    
    # ç”»åƒæŠ½å‡ºè¨­å®š
    st.subheader("ğŸ¨ ç”»åƒæŠ½å‡ºè¨­å®š")
    
    extraction_method = st.selectbox(
        "æŠ½å‡ºæ–¹æ³•",
        options=["high_quality", "medium_quality", "embedded", "combined"],
        format_func=lambda x: {
            "high_quality": "é«˜å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "medium_quality": "ä¸­å“è³ªï¼ˆãƒšãƒ¼ã‚¸å…¨ä½“ï¼‰",
            "embedded": "åŸ‹ã‚è¾¼ã¿ç”»åƒï¼ˆä½ç½®ãƒ™ãƒ¼ã‚¹ï¼‰",
            "combined": "å…¨ã¦ï¼ˆãƒšãƒ¼ã‚¸+åŸ‹ã‚è¾¼ã¿ï¼‰"
        }[x],
        index=0
    )
    
    if extraction_method in ["high_quality", "medium_quality", "combined"]:
        dpi = st.slider("è§£åƒåº¦ï¼ˆDPIï¼‰", 72, 300, 200, 50)
    else:
        dpi = 150
    
    st.markdown("---")
    
    # ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨­å®š
    st.subheader("ğŸ¤– LLMè¨­å®š")
    use_multimodal = st.checkbox(
        "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMä½¿ç”¨ï¼ˆç”»åƒç†è§£ï¼‰",
        value=False,
        help="GPT-4 Visionã§ç”»åƒã‚‚ç†è§£ï¼ˆé–‹ç™ºä¸­ï¼‰"
    )
    st.session_state.use_multimodal = use_multimodal
    
    if use_multimodal:
        st.info("ğŸ”¬ å®Ÿé¨“çš„æ©Ÿèƒ½: ç”»åƒ+ãƒ†ã‚­ã‚¹ãƒˆã‚’åŒæ™‚åˆ†æ")
    
    st.markdown("---")
    
    # çµ±è¨ˆæƒ…å ±
    st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    data_dir = Path("./uploaded_data")
    if data_dir.exists():
        files = list(data_dir.glob("*.*"))
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", len(files))
    else:
        st.metric("ãƒ•ã‚¡ã‚¤ãƒ«", 0)
    
    total_images = len(st.session_state.image_registry)
    if total_images > 0:
        st.metric("ç”»åƒ", total_images)
    
    if st.session_state.index_created:
        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆæ¸ˆã¿")
    else:
        st.info("â„¹ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœªä½œæˆ")
    
    st.markdown("---")
    
    # è¡¨ç¤ºè¨­å®š
    st.subheader("ğŸ‘ï¸ è¡¨ç¤ºè¨­å®š")
    show_images_in_chat = st.checkbox("ãƒãƒ£ãƒƒãƒˆã«ç”»åƒã‚’è¡¨ç¤º", value=True)
    
    st.markdown("---")
    
    # ãƒªã‚»ãƒƒãƒˆ
    if st.button("ğŸ—‘ï¸ å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ", type="secondary"):
        if st.session_state.get("confirm_reset", False):
            if data_dir.exists():
                shutil.rmtree(data_dir)
                data_dir.mkdir()
            
            chroma_dir = Path("./chroma_db")
            if chroma_dir.exists():
                shutil.rmtree(chroma_dir)
                chroma_dir.mkdir()
            
            st.session_state.index_created = False
            st.session_state.messages = []
            st.session_state.pdf_images = {}
            st.session_state.image_registry = {}
            st.cache_resource.clear()
            st.success("âœ… ãƒªã‚»ãƒƒãƒˆå®Œäº†")
            st.session_state.confirm_reset = False
            st.rerun()
        else:
            st.session_state.confirm_reset = True
            st.warning("âš ï¸ ã‚‚ã†ä¸€åº¦ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç¢ºèª")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not api_key_input:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

tab1, tab2, tab3 = st.tabs(["ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†", "ğŸ’¬ è³ªå•å¿œç­”", "ğŸ–¼ï¸ ç”»åƒã‚®ãƒ£ãƒ©ãƒªãƒ¼"])

with tab1:
    st.header("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_files = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            accept_multiple_files=True,
            type=["txt", "pdf", "md"]
        )
        
        if uploaded_files:
            data_dir = Path("./uploaded_data")
            data_dir.mkdir(exist_ok=True)
            
            for uploaded_file in uploaded_files:
                file_path = data_dir / uploaded_file.name
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
            
            st.success(f"âœ… {len(uploaded_files)}ä»¶ä¿å­˜")
    
    with col2:
        st.subheader("ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
        data_dir = Path("./uploaded_data")
        if data_dir.exists():
            files = list(data_dir.glob("*.*"))
            for file in files:
                size_kb = file.stat().st_size / 1024
                st.text(f"ğŸ“„ {file.name} ({size_kb:.1f}KB)")
    
    st.markdown("---")
    
    if st.button("ğŸ”¨ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ", type="primary", use_container_width=True):
        data_dir = Path("./uploaded_data")
        
        if not data_dir.exists() or not list(data_dir.glob("*.*")):
            st.error("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆä¸­..."):
                try:
                    chroma_client = get_chroma_client()
                    storage_context = initialize_rag_system(chroma_client)
                    
                    index, error = load_and_index_documents(
                        str(data_dir), 
                        storage_context,
                        extraction_method,
                        dpi
                    )
                    
                    if error:
                        st.error(f"âŒ {error}")
                    else:
                        st.session_state.index = index
                        st.session_state.index_created = True
                        st.success("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")
                        st.balloons()
                except Exception as e:
                    import traceback
                    st.error(f"âŒ {str(e)}")
                    with st.expander("è©³ç´°"):
                        st.code(traceback.format_exc())

with tab2:
    st.header("ğŸ’¬ è³ªå•å¿œç­”")
    
    if not st.session_state.index_created:
        st.warning("âš ï¸ ã¾ãšã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„")
    else:
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                if message["role"] == "assistant" and "images" in message and message["images"] and show_images_in_chat:
                    st.markdown("---")
                    st.markdown("**ğŸ“¸ é–¢é€£ç”»åƒ:**")
                    cols = st.columns(min(3, len(message["images"])))
                    for idx, img_data in enumerate(message["images"]):
                        with cols[idx % 3]:
                            caption = f"{img_data['file_name']} - Page {img_data['page']}"
                            st.image(img_data["image"], caption=caption, use_container_width=True)
                
                if "sources" in message and message["sources"]:
                    with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                        for i, source in enumerate(message["sources"]):
                            st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source.get('file_name', 'Unknown')} (Page {source.get('page', '?')})")
                            st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                            st.text(source["text"][:200] + "...")
                            st.divider()
        
        # è³ªå•å…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
                    try:
                        query_engine = st.session_state.index.as_query_engine(
                            similarity_top_k=3,
                            response_mode="compact"
                        )
                        
                        response = query_engine.query(prompt)
                        st.markdown(response.response)
                        
                        # ğŸ†• Nodeã‹ã‚‰ç›´æ¥ç”»åƒã‚’å–å¾—
                        sources = []
                        all_images = []
                        
                        for node in response.source_nodes:
                            sources.append({
                                "text": node.text,
                                "score": node.score,
                                "file_name": node.metadata.get("file_name", "Unknown"),
                                "page": node.metadata.get("page", "?")
                            })
                            
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã‚’å–å¾—
                            node_images = get_images_from_node(node)
                            all_images.extend(node_images)
                        
                        # é‡è¤‡å‰Šé™¤
                        seen = set()
                        unique_images = []
                        for img in all_images:
                            key = (img['file_name'], img['page'], img['type'])
                            if key not in seen:
                                seen.add(key)
                                unique_images.append(img)
                        
                        # ç”»åƒè¡¨ç¤º
                        if unique_images and show_images_in_chat:
                            st.markdown("---")
                            st.markdown("**ğŸ“¸ é–¢é€£ç”»åƒ:**")
                            cols = st.columns(min(3, len(unique_images)))
                            for idx, img_data in enumerate(unique_images[:6]):
                                with cols[idx % 3]:
                                    caption = f"{img_data['file_name']} - Page {img_data['page']}"
                                    st.image(img_data["image"], caption=caption, use_container_width=True)
                        
                        # å‚ç…§å…ƒè¡¨ç¤º
                        if sources:
                            with st.expander("ğŸ“š å‚ç…§å…ƒ"):
                                for i, source in enumerate(sources):
                                    st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - {source['file_name']} (Page {source['page']})")
                                    st.markdown(f"é–¢é€£åº¦: {source['score']:.3f}")
                                    st.text(source["text"][:200] + "...")
                                    st.divider()
                        
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": response.response,
                            "sources": sources,
                            "images": unique_images
                        })
                    except Exception as e:
                        error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
                        st.error(error_msg)
                        st.session_state.messages.append({"role": "assistant", "content": error_msg})

with tab3:
    st.header("ğŸ–¼ï¸ ç”»åƒã‚®ãƒ£ãƒ©ãƒªãƒ¼")
    
    if not st.session_state.pdf_images:
        st.info("ğŸ“„ ç”»åƒãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™")
    else:
        for pdf_name, images in st.session_state.pdf_images.items():
            with st.expander(f"ğŸ“„ {pdf_name} ({len(images)}æš)", expanded=True):
                # ãƒšãƒ¼ã‚¸ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                pages = {}
                for img in images:
                    page = img["page"]
                    if page not in pages:
                        pages[page] = []
                    pages[page].append(img)
                
                for page_num in sorted(pages.keys()):
                    st.markdown(f"**Page {page_num}**")
                    page_images = pages[page_num]
                    cols = st.columns(3)
                    for idx, img_data in enumerate(page_images):
                        with cols[idx % 3]:
                            st.image(img_data["image"], use_container_width=True)
                            
                            img_bytes = io.BytesIO()
                            img_data["image"].save(img_bytes, format="PNG")
                            st.download_button(
                                "ğŸ’¾",
                                img_bytes.getvalue(),
                                f"{pdf_name}_p{page_num}_{idx}.png",
                                "image/png",
                                key=f"dl_{pdf_name}_{page_num}_{idx}"
                            )
                    st.markdown("---")

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ” ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ  v2.0 | ãƒšãƒ¼ã‚¸åˆ†å‰²ãƒ»ç”»åƒç´ä»˜ã‘ãƒ»ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ
    </div>
    """,
    unsafe_allow_html=True
)